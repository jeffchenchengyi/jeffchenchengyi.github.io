{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3fae24",
   "metadata": {},
   "source": [
    "# Uplift Modelling and Contextual Bandits [In Progress]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66cf7b",
   "metadata": {},
   "source": [
    "By: Chengyi (Jeff) Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d6db60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n\\nimport causalml\\nimport obp\";\n",
       "                var nbb_formatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n\\nimport causalml\\nimport obp\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "%load_ext nb_black\n",
    "\n",
    "import causalml\n",
    "import obp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e809c87",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28611a09",
   "metadata": {},
   "source": [
    "Having worked with uplift modelling at Shopee and contextual bandits at Gojek, I've come to realize huge similarities between the way these two seemingly disparate problems are modelled. In the following post, I'll do my best to reconcile the relationship between these two modelling approaches and show how uplift modelling is simply a subclass of contextual bandits. I'll be going through uplift modelling with the help of Uber's [Causal ML](https://causalml.readthedocs.io/en/latest/index.html) package and contextual bandits with [Open Bandit Pipeline](https://zr-obp.readthedocs.io/en/latest/index.html). In particular, I'm interested in comparing the different algorithms used for off-policy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829e262",
   "metadata": {},
   "source": [
    "---\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527263d1",
   "metadata": {},
   "source": [
    "### What is uplift modelling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab365a9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03dc37c1",
   "metadata": {},
   "source": [
    "### What are contextual bandits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c94eebb",
   "metadata": {},
   "source": [
    "#### 1. [Multi-armed Bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4740347",
   "metadata": {},
   "source": [
    "#### 2. Contextual Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d0a1d",
   "metadata": {},
   "source": [
    "#### 3. Full Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e8577",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/89396/multi-armed-bandit-algorithms-vs-uplift-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8ffa8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "chronic-senator",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.2. Off-Policy Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-breakfast",
   "metadata": {},
   "source": [
    "### 15.2.1 T-distribution (Population Variance Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_t_bound(**kwargs):\n",
    "    \"\"\"Calculates the Student T's confidence interval for the V_ips estimator\n",
    "    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower bound of V(π), upper bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    t_score = sp.stats.t.ppf(1 - kwargs[\"δ\"] / 2)\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"V_ips\"] - t_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "    ub = min(1, max(0, kwargs[\"V_ips\"] + t_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-parliament",
   "metadata": {},
   "source": [
    "### 15.2.2 Asymptotically Gaussian (Central Limit Theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic_gaussian_bound(**kwargs):\n",
    "    \"\"\"Calculates the asymptotically Gaussian confidence interval for the V_ips estimator\n",
    "    As n --> \\infty, by CLT, sampling distribution of the sample mean of the random variable,\n",
    "    in our case: importance-weighted rewards are our random variable α.\n",
    "    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n\n",
    "    \n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower bound of V(π), upper bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    z_score = sp.stats.norm.ppf(1 - kwargs[\"δ\"] / 2)\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"V_ips\"] - z_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "    ub = min(1, max(0, kwargs[\"V_ips\"] + z_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-aerospace",
   "metadata": {},
   "source": [
    "### 15.2.3 Clopper-Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clopper_pearson_bound(**kwargs):\n",
    "    \"\"\"Calculates the clopper pearson bound for the V_ips estimator\n",
    "    0 <= V(π) <= 1\n",
    "    https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower clopper-pearson bound of V(π), upper clopper-pearson bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    k = kwargs[\"V_ips\"] * kwargs[\"n\"] / kwargs[\"w_max\"]\n",
    "\n",
    "    lb = sp.special.betaincinv(k, kwargs[\"n\"] - k + 1, kwargs[\"δ\"] / 2) if k > 0 and kwargs[\"n\"] - k + 1 > 0 else 0\n",
    "    ub = sp.special.betaincinv(k + 1, kwargs[\"n\"] - k, 1 - (kwargs[\"δ\"]/2)) if kwargs[\"n\"] > k else 1\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"w_max\"] * lb))\n",
    "    ub = min(1, max(0, kwargs[\"w_max\"] * ub))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-mapping",
   "metadata": {},
   "source": [
    "### 15.2.4 Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opened-winning",
   "metadata": {},
   "source": [
    "### 15.2.5 Concentration Inequality: Hoeffding Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-marine",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    {\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-portal",
   "metadata": {},
   "source": [
    "Hoeffding's Inequality: Let $X_1, ..., X_n$ be independent random variables strictly bounded by the interval $[a_i, b_i]$, $a_i \\leq X_i \\leq b_i$. We define the empirical mean of these variables by $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$, such that\n",
    "\n",
    "\\begin{align}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert \\geq \\epsilon) \\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-david",
   "metadata": {},
   "source": [
    "From Hoeffding's Inequality:\n",
    "\\begin{align}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert \\geq \\epsilon) &\\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "1 - P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\epsilon) &\\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-senegal",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\label{eq:1}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\epsilon) \\geq \\underbrace{1 - 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)}}_{1-\\delta}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-demonstration",
   "metadata": {},
   "source": [
    "Finding $\\epsilon$:\n",
    "\n",
    "\\begin{align}\n",
    "\\therefore 1-\\delta &= 1 - 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\delta &= 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\ln{\\delta} &= \\ln{2} - \\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2} \\\\\n",
    "\\ln{\\frac{2}{\\delta}} &= \\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2} \\\\\n",
    "2n^2\\epsilon^2 &= \\sum_{i=1}^{n}{(b_i - a_i)}^2 \\ln{\\frac{2}{\\delta}} \\\\\n",
    "\\epsilon &= \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-affair",
   "metadata": {},
   "source": [
    "Substituting $\\epsilon$ into Equation 1, we get our Hoeffding Bound Confidence Intervals:\n",
    "\n",
    "\\begin{align}\n",
    "P\\Bigg(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(-\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}< \\bar{X} - \\mathbb{E}[\\bar{X}] < \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\bar{X}-\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}< \\mathbb{E}[\\bar{X}] < \\bar{X}+\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-smith",
   "metadata": {},
   "source": [
    "Assuming that propensity scores $\\alpha_i$ are bounded between $[0, w_{max}=\\text{max}_{i\\in n}\\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i)}r_i]$, we can substitute the following:\n",
    "- $\\mathbb{E}[\\bar{X}]: V(\\pi)$\n",
    "- $X_i: \\alpha_i = \\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i}r_i$\n",
    "- $\\bar{X}: \\hat{V_{\\text{IPS}}}(\\pi) = \\frac{1}{n} \\sum_{i=1}^{n}\\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i)}r_i$\n",
    "- $b_i: w_{max}$\n",
    "- $a_i: 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-master",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-\\sqrt{\\frac{\\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+\\sqrt{\\frac{\\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-\\sqrt{\\frac{nw^2_{max}}{2n^2} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+\\sqrt{\\frac{nw^2_{max}}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-w_{max}\\sqrt{\\frac{1}{2n} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+w_{max}\\sqrt{\\frac{1}{2n} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_bound(**kwargs):\n",
    "    \"\"\"Calculates the empirical hoeffding bounds for the V_ips estimator\n",
    "    using the Hoeffding Inequality\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. Default = 0.05, meaning a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower empirical hoeffding bound of V(π), upper empirical hoeffding bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    ε = kwargs[\"w_max\"] * np.sqrt((1 / (2 * kwargs[\"n\"])) * np.log(2 / kwargs[\"δ\"]))\n",
    "    lb, ub = kwargs[\"V_ips\"] - ε, kwargs[\"V_ips\"] + ε\n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-sellers",
   "metadata": {},
   "source": [
    "### 15.2.6 Concentration Inequality: Bernstein Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-correction",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    {\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    } \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-sapphire",
   "metadata": {},
   "source": [
    "Bernstein Inequality: Suppose $X_1, \\cdots, X_n$ are $i.i.d.$ with 0 mean, variance $\\sigma^2$ and $\\vert X_i \\vert \\leq M$ almost surely,\n",
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg({\n",
    "        \\left\\vert\n",
    "            \\frac{1}{n}\\sum^{n}_{i=1} X_i\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\\frac{2\\sigma^2}{n}\\log\\frac{2}{\\delta}} \n",
    "        + \\frac{2M}{3n}{\\log\\frac{2}{\\delta}}\n",
    "    }\\Bigg) \\geq 1 - \\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-spyware",
   "metadata": {},
   "source": [
    "Since $V_{\\text{IPS}}(\\pi)$ is an unbiased estimator of $V(\\pi)$, $\\hat{V}_{\\text{IPS}}{(\\pi)} - {V}(\\pi)$ has 0 mean, and variance of $Var[\\hat{V}_{\\text{IPS}}(\\pi)]$, and setting $M: w_{max}$,\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg({\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg) \\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-constitution",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg(\\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "    -\n",
    "    \\Bigg({\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg)\n",
    "    &\\leq\n",
    "    {V}(\\pi)\n",
    "    \\leq\n",
    "    \\hat{V}_{\\text{IPS}}{(\\pi)}\n",
    "    +\n",
    "    \\Bigg({\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg\n",
    "    )\n",
    "    \\Bigg) &\\geq 1 - \\delta \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernstein_bound(**kwargs):\n",
    "    \"\"\"Calculates the empirical benrstein bounds for the V_ips estimator\n",
    "    using the Bernstein Inequality\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower empirical bernstein bound of V(π), upper empirical bernstein bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    ε = np.sqrt(2 * np.log(2 / kwargs[\"δ\"]) * kwargs[\"var_V_ips\"]) + (\n",
    "        2 * kwargs[\"w_max\"] * np.log(2 / kwargs[\"δ\"])\n",
    "    ) / (3 * kwargs[\"n\"])\n",
    "\n",
    "    # ε = np.sqrt(\n",
    "    #     2 * np.log(2 / kwargs[\"δ\"]) * (kwargs[\"var_V_ips\"] / kwargs[\"n\"])\n",
    "    # ) + (2 * kwargs[\"w_max\"] * np.log(2 / kwargs[\"δ\"])) / (3 * kwargs[\"n\"])\n",
    "\n",
    "    lb, ub = kwargs[\"V_ips\"] - ε, kwargs[\"V_ips\"] + ε\n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-future",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.3. Online Learning: Context-free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-thanks",
   "metadata": {},
   "source": [
    "### 15.3.1 Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-victoria",
   "metadata": {},
   "source": [
    "### 15.3.2 Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-faculty",
   "metadata": {},
   "source": [
    "### 15.3.3 Bernoulli Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-black",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.4. Online Learning: Contextual (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-halloween",
   "metadata": {},
   "source": [
    "### 15.4.1 Linear Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-rings",
   "metadata": {},
   "source": [
    "### 15.4.2 Linear Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-shoulder",
   "metadata": {},
   "source": [
    "### 15.4.3 Linear Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-robertson",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.5. Online Learning: Contextual (Logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-interval",
   "metadata": {},
   "source": [
    "### 15.5.1 Logistic Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-patio",
   "metadata": {},
   "source": [
    "### 15.5.2 Logistic Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-planet",
   "metadata": {},
   "source": [
    "### 15.5.3 Logistic Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-modeling",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.6. Offline (Off-Policy) Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-raleigh",
   "metadata": {},
   "source": [
    "### 15.6.1 Inverse Probability Weighting (IPW) Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-mineral",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29cf8e2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
