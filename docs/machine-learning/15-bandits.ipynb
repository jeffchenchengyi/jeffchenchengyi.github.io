{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "external-video",
   "metadata": {},
   "source": [
    "# 15. Bandits [In Progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thermal-version",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.83 s (started: 2021-04-07 09:26:26 +08:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n%matplotlib inline\\n\\nimport os\\nfrom collections import defaultdict\\nimport torch\\nimport numpy as np\\nimport pandas as pd\\nimport cvxpy as cp\\nimport scipy.stats as sp\\nfrom scipy import optimize\\nfrom sympy import *\\nfrom torch.distributions import constraints\\nimport matplotlib.pyplot as plt\\n\\nplt.rcParams[\\\"figure.dpi\\\"] = 300\\nplt.rcParams[\\\"figure.figsize\\\"] = (16, 12)\\n\\nimport pyro\\nimport pyro.distributions as dist\\nfrom pyro import poutine\\nfrom pyro.infer.autoguide import AutoDelta\\nfrom pyro.optim import Adam\\nfrom pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\\n\\nsmoke_test = \\\"CI\\\" in os.environ\\nassert pyro.__version__.startswith(\\\"1.5.1\\\")\\npyro.enable_validation(True)\";\n",
       "                var nbb_formatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n%matplotlib inline\\n\\nimport os\\nfrom collections import defaultdict\\nimport torch\\nimport numpy as np\\nimport pandas as pd\\nimport cvxpy as cp\\nimport scipy.stats as sp\\nfrom scipy import optimize\\nfrom sympy import *\\nfrom torch.distributions import constraints\\nimport matplotlib.pyplot as plt\\n\\nplt.rcParams[\\\"figure.dpi\\\"] = 300\\nplt.rcParams[\\\"figure.figsize\\\"] = (16, 12)\\n\\nimport pyro\\nimport pyro.distributions as dist\\nfrom pyro import poutine\\nfrom pyro.infer.autoguide import AutoDelta\\nfrom pyro.optim import Adam\\nfrom pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\\n\\nsmoke_test = \\\"CI\\\" in os.environ\\nassert pyro.__version__.startswith(\\\"1.5.1\\\")\\npyro.enable_validation(True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "%load_ext nb_black\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "from sympy import *\n",
    "from torch.distributions import constraints\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"1.5.1\")\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-friendly",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.1. Off-Policy Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-payment",
   "metadata": {},
   "source": [
    "### 15.1.1 Replay Method (RM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-princeton",
   "metadata": {},
   "source": [
    "### 15.1.2 Direct Method (DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-cornell",
   "metadata": {},
   "source": [
    "### 15.1.3 Inverse Probability Weighting (IPW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-promise",
   "metadata": {},
   "source": [
    "### 15.1.4 Self-Normalized Inverse Probability Weighting (SNIPW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-liechtenstein",
   "metadata": {},
   "source": [
    "### 15.1.5 Doubly Robust (DR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-flower",
   "metadata": {},
   "source": [
    "### 15.1.6 Switch Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-corruption",
   "metadata": {},
   "source": [
    "### 15.1.7 More Robust Doubly Robust (MRDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-correlation",
   "metadata": {},
   "source": [
    "### 15.1.8 Doubly Robust with Optimistic Shrinkage (DRos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-amber",
   "metadata": {},
   "source": [
    "### 15.1.9 Double Machine Learning (DML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-senator",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.2. Off-Policy Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-breakfast",
   "metadata": {},
   "source": [
    "### 15.2.1 T-distribution (Population Variance Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_t_bound(**kwargs):\n",
    "    \"\"\"Calculates the Student T's confidence interval for the V_ips estimator\n",
    "    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower bound of V(π), upper bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    t_score = sp.stats.t.ppf(1 - kwargs[\"δ\"] / 2)\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"V_ips\"] - t_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "    ub = min(1, max(0, kwargs[\"V_ips\"] + t_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-parliament",
   "metadata": {},
   "source": [
    "### 15.2.2 Asymptotically Gaussian (Central Limit Theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic_gaussian_bound(**kwargs):\n",
    "    \"\"\"Calculates the asymptotically Gaussian confidence interval for the V_ips estimator\n",
    "    As n --> \\infty, by CLT, sampling distribution of the sample mean of the random variable,\n",
    "    in our case: importance-weighted rewards are our random variable α.\n",
    "    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n\n",
    "    \n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower bound of V(π), upper bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    z_score = sp.stats.norm.ppf(1 - kwargs[\"δ\"] / 2)\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"V_ips\"] - z_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "    ub = min(1, max(0, kwargs[\"V_ips\"] + z_score*(kwargs[\"var_V_ips\"]**0.5)))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-aerospace",
   "metadata": {},
   "source": [
    "### 15.2.3 Clopper-Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clopper_pearson_bound(**kwargs):\n",
    "    \"\"\"Calculates the clopper pearson bound for the V_ips estimator\n",
    "    0 <= V(π) <= 1\n",
    "    https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower clopper-pearson bound of V(π), upper clopper-pearson bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    k = kwargs[\"V_ips\"] * kwargs[\"n\"] / kwargs[\"w_max\"]\n",
    "\n",
    "    lb = sp.special.betaincinv(k, kwargs[\"n\"] - k + 1, kwargs[\"δ\"] / 2) if k > 0 and kwargs[\"n\"] - k + 1 > 0 else 0\n",
    "    ub = sp.special.betaincinv(k + 1, kwargs[\"n\"] - k, 1 - (kwargs[\"δ\"]/2)) if kwargs[\"n\"] > k else 1\n",
    "\n",
    "    lb = min(1, max(0, kwargs[\"w_max\"] * lb))\n",
    "    ub = min(1, max(0, kwargs[\"w_max\"] * ub))\n",
    "\n",
    "    return min(lb, ub), max(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-mapping",
   "metadata": {},
   "source": [
    "### 15.2.4 Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opened-winning",
   "metadata": {},
   "source": [
    "### 15.2.5 Concentration Inequality: Hoeffding Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-marine",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    {\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-portal",
   "metadata": {},
   "source": [
    "Hoeffding's Inequality: Let $X_1, ..., X_n$ be independent random variables strictly bounded by the interval $[a_i, b_i]$, $a_i \\leq X_i \\leq b_i$. We define the empirical mean of these variables by $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$, such that\n",
    "\n",
    "\\begin{align}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert \\geq \\epsilon) \\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-david",
   "metadata": {},
   "source": [
    "From Hoeffding's Inequality:\n",
    "\\begin{align}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert \\geq \\epsilon) &\\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "1 - P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\epsilon) &\\leq 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-senegal",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\label{eq:1}\n",
    "P(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\epsilon) \\geq \\underbrace{1 - 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)}}_{1-\\delta}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-demonstration",
   "metadata": {},
   "source": [
    "Finding $\\epsilon$:\n",
    "\n",
    "\\begin{align}\n",
    "\\therefore 1-\\delta &= 1 - 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\delta &= 2{e}^{\\Big(-\\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2}\\Big)} \\\\\n",
    "\\ln{\\delta} &= \\ln{2} - \\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2} \\\\\n",
    "\\ln{\\frac{2}{\\delta}} &= \\frac{2n^2\\epsilon^2}{\\sum_{i=1}^{n}{(b_i - a_i)}^2} \\\\\n",
    "2n^2\\epsilon^2 &= \\sum_{i=1}^{n}{(b_i - a_i)}^2 \\ln{\\frac{2}{\\delta}} \\\\\n",
    "\\epsilon &= \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-affair",
   "metadata": {},
   "source": [
    "Substituting $\\epsilon$ into Equation 1, we get our Hoeffding Bound Confidence Intervals:\n",
    "\n",
    "\\begin{align}\n",
    "P\\Bigg(\\left\\vert \\bar{X} - \\mathbb{E}[\\bar{X}] \\right\\vert < \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(-\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}< \\bar{X} - \\mathbb{E}[\\bar{X}] < \\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\bar{X}-\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}< \\mathbb{E}[\\bar{X}] < \\bar{X}+\\sqrt{\\frac{\\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-smith",
   "metadata": {},
   "source": [
    "Assuming that propensity scores $\\alpha_i$ are bounded between $[0, w_{max}=\\text{max}_{i\\in n}\\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i)}r_i]$, we can substitute the following:\n",
    "- $\\mathbb{E}[\\bar{X}]: V(\\pi)$\n",
    "- $X_i: \\alpha_i = \\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i}r_i$\n",
    "- $\\bar{X}: \\hat{V_{\\text{IPS}}}(\\pi) = \\frac{1}{n} \\sum_{i=1}^{n}\\frac{\\pi(a_i\\vert x_i)}{\\mu(a_i\\vert x_i)}r_i$\n",
    "- $b_i: w_{max}$\n",
    "- $a_i: 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-master",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-\\sqrt{\\frac{\\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+\\sqrt{\\frac{\\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-\\sqrt{\\frac{nw^2_{max}}{2n^2} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+\\sqrt{\\frac{nw^2_{max}}{2n^2} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta \\\\\n",
    "P\\Bigg(\\hat{V_{\\text{IPS}}}(\\pi)-w_{max}\\sqrt{\\frac{1}{2n} \\ln{\\frac{2}{\\delta}}} < V(\\pi) < \\hat{V_{\\text{IPS}}}(\\pi)+w_{max}\\sqrt{\\frac{1}{2n} \\ln{\\frac{2}{\\delta}}}\\Bigg) &\\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_bound(**kwargs):\n",
    "    \"\"\"Calculates the empirical hoeffding bounds for the V_ips estimator\n",
    "    using the Hoeffding Inequality\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. Default = 0.05, meaning a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower empirical hoeffding bound of V(π), upper empirical hoeffding bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    ε = kwargs[\"w_max\"] * np.sqrt((1 / (2 * kwargs[\"n\"])) * np.log(2 / kwargs[\"δ\"]))\n",
    "    lb, ub = kwargs[\"V_ips\"] - ε, kwargs[\"V_ips\"] + ε\n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-sellers",
   "metadata": {},
   "source": [
    "### 15.2.6 Concentration Inequality: Bernstein Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-correction",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    {\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    } \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-sapphire",
   "metadata": {},
   "source": [
    "Bernstein Inequality: Suppose $X_1, \\cdots, X_n$ are $i.i.d.$ with 0 mean, variance $\\sigma^2$ and $\\vert X_i \\vert \\leq M$ almost surely,\n",
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg({\n",
    "        \\left\\vert\n",
    "            \\frac{1}{n}\\sum^{n}_{i=1} X_i\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\\frac{2\\sigma^2}{n}\\log\\frac{2}{\\delta}} \n",
    "        + \\frac{2M}{3n}{\\log\\frac{2}{\\delta}}\n",
    "    }\\Bigg) \\geq 1 - \\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-spyware",
   "metadata": {},
   "source": [
    "Since $V_{\\text{IPS}}(\\pi)$ is an unbiased estimator of $V(\\pi)$, $\\hat{V}_{\\text{IPS}}{(\\pi)} - {V}(\\pi)$ has 0 mean, and variance of $Var[\\hat{V}_{\\text{IPS}}(\\pi)]$, and setting $M: w_{max}$,\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg({\n",
    "        \\left\\vert\n",
    "            \\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "            - {V}(\\pi)\n",
    "        \\right\\vert\n",
    "    } \n",
    "    &\\leq \n",
    "    {\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg) \\geq 1-\\delta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-constitution",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "    P\\Bigg(\\hat{V}_{\\text{IPS}}{(\\pi)} \n",
    "    -\n",
    "    \\Bigg({\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg)\n",
    "    &\\leq\n",
    "    {V}(\\pi)\n",
    "    \\leq\n",
    "    \\hat{V}_{\\text{IPS}}{(\\pi)}\n",
    "    +\n",
    "    \\Bigg({\n",
    "        \\sqrt{\n",
    "            {2\\text{log}\\frac{2}{\\delta}}{\\frac{{\\text{Var}}_{(x, a, r) \\sim \\mu}[\\hat{V}_{\\text{IPS}}{(\\pi)}]}{n}}} \n",
    "        + \\frac{2{\\hat{w}_{max}}}{3n}{\\text{log} \\frac{2}{\\delta}}\n",
    "    }\\Bigg\n",
    "    )\n",
    "    \\Bigg) &\\geq 1 - \\delta \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernstein_bound(**kwargs):\n",
    "    \"\"\"Calculates the empirical benrstein bounds for the V_ips estimator\n",
    "    using the Bernstein Inequality\n",
    "\n",
    "    Args:\n",
    "        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator\n",
    "        var_V_ips (float): Variance of V_ips\n",
    "        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy's probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)\n",
    "        n (int): Size of the logging policy dataset\n",
    "        δ (float): Significance level for confidence coverage. If δ = 0.05, it's a 95% confidence interval\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (lower empirical bernstein bound of V(π), upper empirical bernstein bound of V(π))\n",
    "\n",
    "    \"\"\"\n",
    "    ε = np.sqrt(2 * np.log(2 / kwargs[\"δ\"]) * kwargs[\"var_V_ips\"]) + (\n",
    "        2 * kwargs[\"w_max\"] * np.log(2 / kwargs[\"δ\"])\n",
    "    ) / (3 * kwargs[\"n\"])\n",
    "\n",
    "    # ε = np.sqrt(\n",
    "    #     2 * np.log(2 / kwargs[\"δ\"]) * (kwargs[\"var_V_ips\"] / kwargs[\"n\"])\n",
    "    # ) + (2 * kwargs[\"w_max\"] * np.log(2 / kwargs[\"δ\"])) / (3 * kwargs[\"n\"])\n",
    "\n",
    "    lb, ub = kwargs[\"V_ips\"] - ε, kwargs[\"V_ips\"] + ε\n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-future",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.3. Online Learning: Context-free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-thanks",
   "metadata": {},
   "source": [
    "### 15.3.1 Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-victoria",
   "metadata": {},
   "source": [
    "### 15.3.2 Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-faculty",
   "metadata": {},
   "source": [
    "### 15.3.3 Bernoulli Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-black",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.4. Online Learning: Contextual (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-halloween",
   "metadata": {},
   "source": [
    "### 15.4.1 Linear Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-rings",
   "metadata": {},
   "source": [
    "### 15.4.2 Linear Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-shoulder",
   "metadata": {},
   "source": [
    "### 15.4.3 Linear Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-robertson",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.5. Online Learning: Contextual (Logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-interval",
   "metadata": {},
   "source": [
    "### 15.5.1 Logistic Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-patio",
   "metadata": {},
   "source": [
    "### 15.5.2 Logistic Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-planet",
   "metadata": {},
   "source": [
    "### 15.5.3 Logistic Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-modeling",
   "metadata": {},
   "source": [
    "---\n",
    "## 15.6. Offline (Off-Policy) Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-raleigh",
   "metadata": {},
   "source": [
    "### 15.6.1 Inverse Probability Weighting (IPW) Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-mineral",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
