{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf4a107",
   "metadata": {},
   "source": [
    "# Probabilistic Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e230e5",
   "metadata": {},
   "source": [
    "By: Chengyi (Jeff) Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055c458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "time: 897 µs\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n\\nimport torch\\nimport pyro\\nimport pyro.distributions as dist\";\n",
       "                var nbb_formatted_code = \"%load_ext autotime\\n%load_ext nb_black\\n\\nimport torch\\nimport pyro\\nimport pyro.distributions as dist\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "%load_ext nb_black\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51148111",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d3b33",
   "metadata": {},
   "source": [
    "The purpose of these sets of notes is to connect ideas crossing the realms of frequentist, bayesian, probabilistic machine learning vernacular, e.g. how 1. frequentist maximum likelihood estimation is related to 2. partial bayesian maximum a posteriori and 3. full bayesian inference. I'm in no way an expert of the philosophical and practical differences between the the frequentist vs. bayesian perspective nor am I close to being good at mathematics -- here's just what I've gathered from my readings, subject to my own interpretation. Throughout, I'll be drawing ideas from computer programming as well, specifically notes on [Uber's Pyro PPL](http://pyro.ai/examples/intro_long.html). Starting from first principles, we ask: **\"What are we even trying to do in machine learning?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10dc39",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0cb7c",
   "metadata": {},
   "source": [
    "Before we distinguish between supervised, unsupervised, semi-supervised learning, here's the general probabilistic machine learning setting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467940f",
   "metadata": {},
   "source": [
    "We are given a matrix of observed training data $\\mathbf{X}_{\\text{train}} = \\{ \\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3, \\ldots \\mathbf{x}_N \\}$ as independent samples generated from a true data distribution $f(\\mathcal{X})$, where $\\mathbf{x} \\in \\mathcal{X}$ (the set of observed data values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6b6cd",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311794a",
   "metadata": {},
   "source": [
    "We specify a probabilistic model of the form / factorization structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1c9c4",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta) &= p(\\mathcal{X} \\vert \\mathcal{Z} ; \\Theta = \\theta) p(\\mathcal{Z} ; \\Theta = \\theta) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a52631",
   "metadata": {},
   "source": [
    "to learn $\\mathbf{X}_{\\text{train}}$ to approximate $f(\\mathcal{X})$, where $\\mathbf{z} \\in \\mathcal{Z}$ are a set of latent / unobserved random variables, as we make no assumptions on whether the observable dataset $\\mathbf{X}_{\\text{train}}$ contains all information about the system. This probabilistic model is often called the **complete data likelihood**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccabb9f",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X} ; \\Theta = \\theta) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73120d98",
   "metadata": {},
   "source": [
    "is then called the **incomplete data likelihood** / **evidence** / **marginal likelihood** (because we marginalized out $\\mathcal{Z}$ to keep only $\\mathcal{X}$. $\\Theta = \\theta$ are fixed parameters (\"$;$\" is used instead of \"$\\vert$\" in the conditioning of $\\theta$ to indicate that it is a \"frequentist\" fixed parameter and not a \"bayesian\" random variable). Furthermore, it's called a likelihood function because it is a function over the $\\theta = \\Theta$, the thing we're conditioning on, instead of $\\mathcal{X}$ (fixed because its the data provided) and $\\mathcal{Z}$ (unobserved). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ea288",
   "metadata": {},
   "source": [
    "Learning such a probabilistic model has [2 primary objectives](https://pyro.ai/examples/intro_long.html#Background:-inference,-learning-and-evaluation):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96ad89",
   "metadata": {},
   "source": [
    "#### Objective 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b9bf6",
   "metadata": {},
   "source": [
    "Draw conclusions about the posterior distribution of our latent variables $\\mathcal{Z}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d76057",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{Z} \\vert \\mathcal{X} = \\mathbf{X}_{\\text{train}}; \\Theta = \\theta) \n",
    "    &= \\frac{p(\\mathcal{X} = \\mathbf{X}_{\\text{train}}, \\mathcal{Z}; \\Theta = \\theta)}{\\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}}, \\mathcal{Z} = \\mathbf{z}; \\Theta = \\theta) d\\mathbf{z}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb062c",
   "metadata": {},
   "source": [
    "#### Objective 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f41b76",
   "metadata": {},
   "source": [
    "Make predictions for new data, which we can do with the posterior predictive distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b5e14",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X} = \\mathbf{X}_{\\text{test}} \\vert \\mathcal{X} = \\mathbf{X}_{\\text{train}}; \\Theta = \\theta) &= \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{test}} \\vert \\mathcal{Z} = \\mathbf{z}; \\Theta = \\theta) p(\\mathcal{Z} = \\mathbf{z} \\vert \\mathcal{X} = \\mathbf{X}_{\\text{train}}; \\Theta = \\theta)  d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bf9fd",
   "metadata": {},
   "source": [
    "---\n",
    "## Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45796cd8",
   "metadata": {},
   "source": [
    "### How to find the best $p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e14e22",
   "metadata": {},
   "source": [
    "To learn the $p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta)$, we need to first design a **measure of success** -- how useful our model is / how accurate are we modelling the real life true data distribution. Because we can only observe $\\mathcal{X}$, let's define a \"distance\" measure between our incomplete data likelihood $p(\\mathcal{X} ; \\Theta = \\theta)$ (instead of complete data likelihood because we can't observe it) and the true data distribution $f(\\mathcal{X})$. The smaller the \"distance\" between our 2 distributions the better our model approximates the true data generating process. A common \"distance\" measure between probability distributions is the [KL Divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) (\"distance\" because KL Divergence is asymmetric, does not satisfy triangle inequality, $D_{KL}(P \\vert\\vert Q) \\not= D_{KL}(Q \\vert\\vert P)$). $D_{KL}(f(\\mathcal{X}) \\vert \\vert p(\\mathcal{X};\\Theta=\\theta))$ measures how well [$p$ approximates $f$](https://stats.stackexchange.com/questions/111445/analysis-of-kullback-leibler-divergence):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41eb766",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\theta^* \n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min} D_{KL}(f \\vert \\vert p) \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}\\int_{\\mathbf{x} \\in \\mathcal{X}} f(\\mathcal{X}=\\mathbf{x}) \\log \\frac{f(\\mathcal{X}=\\mathbf{x})}{p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)} d\\mathbf{x} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}\\mathbb{E}_{\\mathbf{x} \\sim f} [\\log f(\\mathcal{X}=\\mathbf{x})] - \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}-\\mathbb{H}[f(\\mathcal{X})] - \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &\\approx \\arg\\underset{\\theta \\in \\Theta}{\\max} \\lim_{N \\rightarrow \\infty} \\frac{1}{N}\\sum_{\\mathbf{x}_i \\in \\mathbf{X}_{\\text{train}}} \\log p(\\mathcal{X}=\\mathbf{x}_i ; \\Theta = \\theta) \\because \\text{law of large numbers} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\prod_{\\mathbf{x}_i \\in \\mathbf{X}_{\\text{train}}} p(\\mathcal{X}=\\mathbf{x}_i ; \\Theta = \\theta) \\because \\log\\text{ is a monotonic increasing function} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta) \\because \\text{i.i.d. data assumption} \\\\\n",
    "    &= \\theta_{\\text{MLE}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f8a30",
   "metadata": {},
   "source": [
    "We have thus arrived at [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) of parameters (you can read more about this derivation method [here](https://slideplayer.com/slide/9502040/) and [here](https://jaketae.github.io/study/kl-mle/)), a pointwise estimate of the parameters that maximizes the incomplete data likelihood (or complete data likelihood when we have no latent variables in the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f0cf9",
   "metadata": {},
   "source": [
    "### Why is MLE a \"frequentist\" inference technique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a98da",
   "metadata": {},
   "source": [
    "The primary reason for why this technique is coined a \"frequentist\" method is because of the assumption that $\\Theta = \\theta$ is a fixed parameter that needs to be estimated, while bayesians believe that $\\Theta = \\theta$ should be a random variable, and hence, have a probability distribution that describes its behavior $p(\\Theta)$, calling it our **prior**. In probabilistic programming / machine learning however, we don't have to worry about these conflicting paradigms. To \"convert\" $\\Theta$ into a random variable instead, we just need to move $\\Theta$ into $\\mathcal{Z}$ and as long as we have a way to model $\\mathcal{Z}$, more specifically $p(\\mathcal{Z} \\vert \\mathcal{X} ; \\Theta = \\theta)$, the **posterior** distribution of our latent variables, we are good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ccafc",
   "metadata": {},
   "source": [
    "### Can we simply find the $\\theta$ that maximizes $p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af791a",
   "metadata": {},
   "source": [
    "Unfortunately, because our model is specified with the latent variables $\\mathcal{Z}$, we can't directly maximize $p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta)$. We'll have to marginalize out the latent variables first as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62029ed",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} ; \\Theta = \\theta) \n",
    "    &= \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}}, \\mathcal{Z} = \\mathbf{z}; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "    &= \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} \\vert \\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) p(\\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdd198",
   "metadata": {},
   "source": [
    "and hence, Maximum Likelihood Estimation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340f531",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\theta^* \n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} \\vert \\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) p(\\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ea4b0",
   "metadata": {},
   "source": [
    "However, this marginalization is often intractable (e.g. if $\\mathcal{Z}$ is a sequence of events, so that the number of values grows exponentially with the sequence length, the exact calculation of the integral will be extremely difficult). Let's instead try to find a lower bound for it by expanding it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5b133",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e27314",
   "metadata": {},
   "source": [
    "### Searching for the ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46e781",
   "metadata": {},
   "source": [
    "Using ideas from importance sampling, assume we have another variational distribution [approximate posterior distribution to $p({\\mathcal{Z}} \\mid {\\mathcal{X}} ; \\Theta = \\theta)$], $q(\\mathcal{Z} ; \\Phi = \\phi)$, where $q(\\mathcal{Z} ; \\Phi = \\phi) > 0$ whenever $p({\\mathcal{Z}}) = \\int_{\\mathbf{x} \\in \\mathcal{X}} p({\\mathcal{X}} = x, {\\mathcal{Z}} \\mid {\\bf \\theta}) > 0$, and we rewite:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fa42f",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\log p(\\mathcal{X} \\mid \\boldsymbol{\\theta }) \n",
    "    &= \\log \\sum_{z \\in \\mathcal{Z}} p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }}) \\frac{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\\\\n",
    "    &= \\log \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\frac{p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})}{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\right] \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83061b",
   "metadata": {},
   "source": [
    "By Jensen's Inequality, given concave function $f(X)$ (e.g. $\\log$), $f\\operatorname {E}\\left[X\\right] \\geq \\operatorname {E}\\left[f(X)\\right]$ {cite}`Variatio28:online`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7466321",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\log p(\\mathcal{X} \\mid \\boldsymbol{\\theta }) \n",
    "    &= \\log \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\frac{p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})}{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\right] \\\\\n",
    "    &\\geq \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log\\left(\\frac{p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})}{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\right)\\right] \\\\\n",
    "    &= \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }}) - \\log q({\\mathcal{Z} = z} \\mid {\\bf \\phi})\\right] \\\\\n",
    "    &= \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})\\right] - \\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log q({\\mathcal{Z} = z} \\mid {\\bf \\phi})\\right] \\\\\n",
    "    &= \\underbrace{\\underbrace{\\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})\\right]}_{\\text{Expected Complete-data Log Likelihood}} + \\underbrace{\\operatorname{H}\\left[\\log q({\\mathcal{Z}} \\mid {\\bf \\phi})\\right]}_{\\text{Entropy of Variational Dist.}}}_{\\text{ELBO / Negative Variational Free Energy } \\mathcal{L}(q({\\mathcal{Z}}\\mid {\\bf \\phi}))} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47116bf0",
   "metadata": {},
   "source": [
    "Hence, we get an ***Evidence Lower Bound (ELBO)*** (also known as the ***Negative Variational Free Energy***) on the $\\log$ Evidence. Instead of an inequality, we can get an exact equality of the form below by deriving the ELBO from rearranging the KL Divergence from our variational distribution (approximate posterior of latent variables) $q({\\mathcal{Z}} \\mid {\\bf \\phi})$ to our actual posterior over latent variables $p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta})$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4eb447",
   "metadata": {},
   "source": [
    "Derivation from ${\\rm KL}(q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\mid\\mid p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta}))$:\n",
    "\n",
    "\\begin{align}\n",
    "    {\\rm KL}(q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\mid\\mid p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta}))\n",
    "    &= \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log\\left(\\frac{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}{p({\\mathcal{Z} = z} \\mid {\\mathcal{x}}, {\\bf \\theta})}\\right)\\right] \\\\\n",
    "    &= \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log q({\\mathcal{Z} = z} \\mid {\\bf \\phi})\\right] - \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log p({\\mathcal{Z} = z} \\mid {\\mathcal{x}}, {\\bf \\theta})\\right] \\\\\n",
    "    &= \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log q({\\mathcal{Z} = z} \\mid {\\bf \\phi})\\right] - \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log p({\\mathcal{Z} = z}, {\\mathcal{x}} \\mid {\\bf \\theta})\\right] + \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log p({\\mathcal{x}} \\mid {\\bf \\theta})\\right] \\\\\n",
    "    &= -\\left[\\operatorname {E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})} \\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})\\right] + \\operatorname{H}\\left[\\log q({\\mathcal{Z}} \\mid {\\bf \\phi})\\right]\\right] + \\operatorname{E}_{q({\\mathcal{Z} = z} \\mid {\\bf \\phi})}\\left[\\log p({\\mathcal{x}} \\mid {\\bf \\theta})\\right] \\\\\n",
    "    &= -\\mathcal{L}(q({\\mathcal{Z} = z}\\mid {\\bf \\phi})) + \\log p({\\mathcal{x}} \\mid {\\bf \\theta}) \\because \\text{Expectation is over latent variables }{\\mathcal{Z} = z}\\text{, which is independent of }{\\mathcal{x}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29b290",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\therefore \\log p({\\mathcal{x}} \\mid {\\bf \\theta}) \n",
    "    &= \\mathcal{L}(q({\\mathcal{Z}} \\mid {\\bf \\phi})) + {\\rm KL}(q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\mid\\mid p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta})) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ce480",
   "metadata": {},
   "source": [
    "Since $\\log p({\\mathcal{x}} \\mid {\\bf \\theta})$ is a constant, maximizing our ELBO / Negative Variational Free Energy will be equivalent to minimizing the ${\\rm KL}(q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\mid\\mid p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta}))$ (0 when $q({\\mathcal{Z}} \\mid {\\bf \\phi}) = p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta})$), making our variational approximation as close as possible to the actual posterior over latents. After this procedure, our 2 tasks will look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f00c75",
   "metadata": {},
   "source": [
    "- 1. Find the MLE (${\\bf\\theta}, {\\bf\\phi}$ are parameters) / MAP (${\\bf\\theta}, {\\bf\\phi}$ are random variables) estimates of the model parameters ${\\bf \\theta_{\\rm{max}}}, {\\bf \\phi_{\\rm{max}}}$ by maximizing the ELBO:\n",
    "\n",
    "\\begin{align}\n",
    "    {\\bf\\theta_{\\rm{max}}} &= \\underset{\\boldsymbol {\\theta}}{\\operatorname{argmax}} \\log p(\\mathcal{X} \\mid \\boldsymbol{\\theta }) \\\\\n",
    "    {\\bf\\theta_{\\rm{max}}}, {\\bf\\phi_{\\rm{max}}} &\\approx \\underset{{\\bf \\theta}, {\\bf \\phi}}{\\operatorname{argmax}} \\mathcal{L}(q({\\mathcal{Z}} \\mid {\\bf \\phi})) \\\\\n",
    "    &= \\underset{{\\bf \\theta}, {\\bf \\phi}}{\\operatorname{argmax}} \\operatorname {E}_{q({\\mathcal{Z}} = z \\mid {\\bf \\phi})} \\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }})\\right] - \\operatorname{H}\\left[\\log q({\\mathcal{Z}} \\mid {\\bf \\phi})\\right]  \\\\\n",
    "\\end{align}\n",
    "\n",
    "In maximizing the ELBO, the first term, Expected Complete-data Log Likelihood, encourages the MLE / MAP estimates of the model parameters to be \n",
    "\n",
    "- 2. Find the posterior over the latent variables $\\mathcal{Z}$, $p(\\mathcal{Z} \\mid \\mathcal{X}, \\boldsymbol {\\theta_{\\rm{max}} })$ {cite}`SVIPartI61:online`:\n",
    "\n",
    "\\begin{align}\n",
    "    p(\\mathcal{Z} \\mid \\mathcal{X}, \\boldsymbol {\\theta_{\\rm{max}} }) &\\approx q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56237b",
   "metadata": {},
   "source": [
    "### Finding the ELBO Part 1: Expectation-Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464296b",
   "metadata": {},
   "source": [
    "The EM algorithm seeks to find the MLE of the evidence / marginal likelihood / incomplete-data likelihood by iteratively applying these two steps {cite}`Expectat45:online`:\n",
    "\n",
    "- 1. Expectation step (E step): Set the approximate posterior / variational distribution $q({\\mathcal{Z}}\\mid {\\bf \\phi}) = p(\\mathcal{Z} \\mid \\mathcal{X}, \\boldsymbol {\\theta_{t} })$, where $\\bf \\theta_{t}$ are the previous M-step estimates of $\\bf \\theta$, this way the ${\\rm KL}(q({\\mathcal{Z}} \\mid {\\bf \\phi}) \\mid\\mid p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta})) = 0$ and $\\log p({\\mathcal{x}} \\mid {\\bf \\theta}) = \\mathcal{L}(p({\\mathcal{Z}} \\mid {\\mathcal{x}}, {\\bf \\theta_{t}}))$. Our objective is then to \n",
    "\n",
    "    - A. Calculate the posterior over latent variables $p(\\mathcal{Z} \\mid \\mathcal{X} ,{\\boldsymbol {\\theta }}^{(t)})$ and \n",
    "    \n",
    "    - B. Calculate $Q({\\boldsymbol {\\theta }}\\mid {\\boldsymbol {\\theta }}^{(t)})$ (Expected Complete data Log Likelihood):\n",
    "\n",
    "\\begin{align}\n",
    "    Q({\\boldsymbol {\\theta }}\\mid {\\boldsymbol {\\theta }}^{(t)}) &= \\operatorname {E} _{p(\\mathcal{Z} = z \\mid \\mathcal{X} ,{\\boldsymbol {\\theta }}^{(t)})}\\left[\\log L({\\boldsymbol {\\theta }};\\mathcal{X} ,\\mathcal{Z} = z )\\right]\\, \\\\\n",
    "    &= \\operatorname {E} _{p(\\mathcal{Z} = z \\mid \\mathcal{X} ,{\\boldsymbol {\\theta }}^{(t)})}\\left[\\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }}) \\right]\\, \\\\\n",
    "    &= \\sum_{z \\in \\mathcal{Z}} p(\\mathcal{Z} = z \\mid \\mathcal{X} ,{\\boldsymbol {\\theta }}^{(t)}) \\log p(\\mathcal{X} ,\\mathcal{Z} = z \\mid {\\boldsymbol {\\theta }}) \\\\\n",
    "\\end{align}\n",
    "\n",
    "Notice that the only thing that is missing from $Q({\\boldsymbol {\\theta }}\\mid {\\boldsymbol {\\theta }}^{(t)})$ compared to the ELBO is the entropy of the approximate posterior distribution $\\operatorname{H}\\left[\\log q({\\mathcal{Z}} \\mid {\\bf \\phi})\\right]$.\n",
    "\n",
    "- 2. Maximization step (M step): Find the parameters that maximize $ Q({\\boldsymbol {\\theta }}\\mid {\\boldsymbol {\\theta }}^{(t)})$:\n",
    "\n",
    "\\begin{align} \n",
    "    {\\boldsymbol {\\theta }}^{(t+1)} &= {\\underset {\\boldsymbol {\\theta }}{\\operatorname {arg\\,max} }}\\ Q({\\boldsymbol {\\theta }}\\mid {\\boldsymbol {\\theta }}^{(t)})\\,\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ffcb3",
   "metadata": {},
   "source": [
    "### Finding the ELBO Part 2: Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7642b2f5",
   "metadata": {},
   "source": [
    "### Finding the ELBO Part 3: Mean-Field Approximate Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc73010",
   "metadata": {},
   "source": [
    "### Finding the ELBO Part 4: Black-Box Stochastic Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3abe7",
   "metadata": {},
   "source": [
    "---\n",
    "## Maximum A Posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a3e33",
   "metadata": {},
   "source": [
    "Before continuing, realize that because "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea8e01",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta) &= p(\\mathcal{Z} \\vert \\mathcal{X}; \\Theta = \\theta) p(\\mathcal{X} ; \\Theta = \\theta)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e1ade",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{Z} \\vert \\mathcal{X}; \\Theta = \\theta) &= \\frac{}{}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93528e",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\frac{1}{N}\\sum_{\\mathbf{x} \\in \\mathbf{x}_{\\text{train}}} \\int_{\\mathbf{z} \\in \\mathcal{Z}} \\log p(\\mathcal{X}=\\mathbf{x}, \\mathcal{Z}=\\mathbf{z}; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a334b",
   "metadata": {},
   "source": [
    "```{note} Mathematical Notation\n",
    "\n",
    "The math notation of my content, including the ones in this post follow the conventions in Christopher M. Bishop's Pattern Recognition and Machine Learning. In addition, I use caligraphic capitalized roman and capitalized greek symbols like $\\mathcal{X}, \\mathcal{Y}, \\mathcal{Z}, \\Omega, \\Psi, \\Xi, \\ldots$ to represent **BOTH** a set of values that the random variables can take as well as the argument of a function in python (e.g. `def p(Θ=θ)`).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea49c1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://pyro.ai/examples/intro_long.html#Background:-inference,-learning-and-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b3bf6",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "\\begin{align}\n",
    "    \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d5121",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45686d56",
   "metadata": {},
   "source": [
    "We're now ready to discuss how MLE is performed in probabilistic machine learning. The key difference between "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ee9d5",
   "metadata": {},
   "source": [
    "Specifically in [Pyro](https://pyro.ai/examples/mle_map.html), to get MLE estimates of $\\theta$, simply declare $\\theta$ as a fixed parameter using `.param` in the `model` and have an empty `guide` (variational distribution). To get MAP estimates instead, declare $\\theta$ just like a regular latent random variable by `.sample` in the `model`, but in the `guide`, declare $\\theta$ as being drawn from a dirac delta function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a9919",
   "metadata": {},
   "source": [
    "### Parameter Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f6e76",
   "metadata": {},
   "source": [
    "Frequentist: Uncertainty is estimated with confidence intervals\n",
    "\n",
    "Bayesian: Uncertainty is estimated with credible intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2d328",
   "metadata": {},
   "source": [
    "### Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb628c",
   "metadata": {},
   "source": [
    "---\n",
    "## Empircal Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79f64d",
   "metadata": {},
   "source": [
    "### Hierarchical Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
