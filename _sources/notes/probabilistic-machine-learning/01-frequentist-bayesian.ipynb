{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988f7073",
   "metadata": {},
   "source": [
    "# Frequentist Vs. Bayesian Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760c8dc",
   "metadata": {},
   "source": [
    "By: Chengyi (Jeff) Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f432d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3587783",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "059bf9fd",
   "metadata": {},
   "source": [
    "---\n",
    "## Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b9c8b",
   "metadata": {},
   "source": [
    "### Derivation 1: KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45796cd8",
   "metadata": {},
   "source": [
    "### How to find the best $p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e14e22",
   "metadata": {},
   "source": [
    "To learn the $p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta)$, we need to first design a **measure of success** -- how useful our model is / how accurate are we modelling the real life true data distribution. Because we can only observe $\\mathcal{X}$, let's define a \"distance\" measure between our incomplete data likelihood $p(\\mathcal{X} ; \\Theta = \\theta)$ (instead of complete data likelihood because we can't observe it) and the true data distribution $f(\\mathcal{X})$. The smaller the \"distance\" between our 2 distributions the better our model approximates the true data generating process. A common \"distance\" measure between probability distributions is the [KL Divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) (\"distance\" because KL Divergence is asymmetric, does not satisfy triangle inequality, $D_{KL}(P \\vert\\vert Q) \\not= D_{KL}(Q \\vert\\vert P)$). $D_{KL}(f(\\mathcal{X}) \\vert \\vert p(\\mathcal{X};\\Theta=\\theta))$ measures how well [$p$ approximates $f$](https://stats.stackexchange.com/questions/111445/analysis-of-kullback-leibler-divergence):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41eb766",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\theta^* \n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min} D_{KL}(f \\vert \\vert p) \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}\\int_{\\mathbf{x} \\in \\mathcal{X}} f(\\mathcal{X}=\\mathbf{x}) \\log \\frac{f(\\mathcal{X}=\\mathbf{x})}{p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)} d\\mathbf{x} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}\\mathbb{E}_{\\mathbf{x} \\sim f} [\\log f(\\mathcal{X}=\\mathbf{x})] - \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\min}-\\mathbb{H}[f(\\mathcal{X})] - \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\mathbb{E}_{\\mathbf{x} \\sim f} [\\log p(\\mathcal{X}=\\mathbf{x} ; \\Theta = \\theta)] \\\\\n",
    "    &\\approx \\arg\\underset{\\theta \\in \\Theta}{\\max} \\lim_{N \\rightarrow \\infty} \\frac{1}{N}\\sum_{\\mathbf{x}_i \\in \\mathbf{X}_{\\text{train}}} \\log p(\\mathcal{X}=\\mathbf{x}_i ; \\Theta = \\theta) \\because \\text{law of large numbers} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\prod_{\\mathbf{x}_i \\in \\mathbf{X}_{\\text{train}}} p(\\mathcal{X}=\\mathbf{x}_i ; \\Theta = \\theta) \\because \\log\\text{ is a monotonic increasing function} \\\\\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta) \\because \\text{i.i.d. data assumption} \\\\\n",
    "    &= \\theta_{\\text{MLE}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f8a30",
   "metadata": {},
   "source": [
    "We have thus arrived at [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) of parameters (you can read more about this derivation method [here](https://slideplayer.com/slide/9502040/) and [here](https://jaketae.github.io/study/kl-mle/)), a pointwise estimate of the parameters that maximizes the incomplete data likelihood (or complete data likelihood when we have no latent variables in the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea63757",
   "metadata": {},
   "source": [
    "### Derivation 2: Posterior with Uniform Prior on Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f0cf9",
   "metadata": {},
   "source": [
    "### Why is MLE a \"frequentist\" inference technique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a98da",
   "metadata": {},
   "source": [
    "The primary reason for why this technique is coined a \"frequentist\" method is because of the assumption that $\\Theta = \\theta$ is a fixed parameter that needs to be estimated, while bayesians believe that $\\Theta = \\theta$ should be a random variable, and hence, have a probability distribution that describes its behavior $p(\\Theta)$, calling it our **prior**. In probabilistic programming / machine learning however, we don't have to worry about these conflicting paradigms. To \"convert\" $\\Theta$ into a random variable instead, we just need to move $\\Theta$ into $\\mathcal{Z}$ and as long as we have a way to model $\\mathcal{Z}$, more specifically $p(\\mathcal{Z} \\vert \\mathcal{X} ; \\Theta = \\theta)$, the **posterior** distribution of our latent variables, we are good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ccafc",
   "metadata": {},
   "source": [
    "### Can we simply find the $\\theta$ that maximizes $p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af791a",
   "metadata": {},
   "source": [
    "Unfortunately, because our model is specified with the latent variables $\\mathcal{Z}$, we can't directly maximize $p(\\mathcal{X}=\\mathbf{X}_{\\text{train}} ; \\Theta = \\theta)$. We'll have to marginalize out the latent variables first as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62029ed",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} ; \\Theta = \\theta) \n",
    "    &= \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}}, \\mathcal{Z} = \\mathbf{z}; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "    &= \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} \\vert \\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) p(\\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdd198",
   "metadata": {},
   "source": [
    "and hence, Maximum Likelihood Estimation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340f531",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\theta^* \n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\int_{\\mathbf{z} \\in \\mathcal{Z}} p(\\mathcal{X} = \\mathbf{X}_{\\text{train}} \\vert \\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) p(\\mathcal{Z} = \\mathbf{z} ; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ea4b0",
   "metadata": {},
   "source": [
    "However, this marginalization is often intractable (e.g. if $\\mathcal{Z}$ is a sequence of events, so that the number of values grows exponentially with the sequence length, the exact calculation of the integral will be extremely difficult). Let's instead try to find a lower bound for it by expanding it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3abe7",
   "metadata": {},
   "source": [
    "---\n",
    "## Maximum A Posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7ed51",
   "metadata": {},
   "source": [
    "### Derivation 1: Computationally Inconvienient to calculate the full Posterior $p(\\mathcal{\\Theta} \\vert \\mathcal{X} = \\mathbf{X}_{\\text{train}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a3e33",
   "metadata": {},
   "source": [
    "Before continuing, realize that because "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea8e01",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{X}, \\mathcal{Z} ; \\Theta = \\theta) &= p(\\mathcal{Z} \\vert \\mathcal{X}; \\Theta = \\theta) p(\\mathcal{X} ; \\Theta = \\theta)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e1ade",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(\\mathcal{Z} \\vert \\mathcal{X}; \\Theta = \\theta) &= \\frac{}{}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93528e",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    &= \\arg\\underset{\\theta \\in \\Theta}{\\max} \\frac{1}{N}\\sum_{\\mathbf{x} \\in \\mathbf{x}_{\\text{train}}} \\int_{\\mathbf{z} \\in \\mathcal{Z}} \\log p(\\mathcal{X}=\\mathbf{x}, \\mathcal{Z}=\\mathbf{z}; \\Theta = \\theta) d\\mathbf{z} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a334b",
   "metadata": {},
   "source": [
    "```{note} Mathematical Notation\n",
    "\n",
    "The math notation of my content, including the ones in this post follow the conventions in Christopher M. Bishop's Pattern Recognition and Machine Learning. In addition, I use caligraphic capitalized roman and capitalized greek symbols like $\\mathcal{X}, \\mathcal{Y}, \\mathcal{Z}, \\Omega, \\Psi, \\Xi, \\ldots$ to represent **BOTH** a set of values that the random variables can take as well as the argument of a function in python (e.g. `def p(Θ=θ)`).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea49c1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://pyro.ai/examples/intro_long.html#Background:-inference,-learning-and-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b3bf6",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "\\begin{align}\n",
    "    \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a5cb5",
   "metadata": {},
   "source": [
    "### Derivation 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a9919",
   "metadata": {},
   "source": [
    "### Parameter Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f6e76",
   "metadata": {},
   "source": [
    "Frequentist: Uncertainty is estimated with confidence intervals\n",
    "\n",
    "Bayesian: Uncertainty is estimated with credible intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2d328",
   "metadata": {},
   "source": [
    "### Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1ddcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1cb628c",
   "metadata": {},
   "source": [
    "---\n",
    "## Empircal Bayes; Type II Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79f64d",
   "metadata": {},
   "source": [
    "---\n",
    "## Hierarchical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd1364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
