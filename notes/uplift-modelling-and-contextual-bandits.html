
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Uplift Modelling and Contextual Bandits [In Progress] &#8212; ΨΦ</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jeffchenchengyi.github.io/notes/uplift-modelling-and-contextual-bandits.html" />
    <link rel="shortcut icon" href="../_static/jeffchenchengyi2019.jpg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Probabilistic Machine Learning" href="probabilistic-machine-learning/00-objective.html" />
    <link rel="prev" title="Machine Learning InFrequently Asked Questions" href="ml-ifaqs.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://jeffchenchengyi.github.io/notes/uplift-modelling-and-contextual-bandits.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Uplift Modelling and Contextual Bandits [In Progress]" />
<meta property="og:description" content="Uplift Modelling and Contextual Bandits [In Progress]  By: Chengyi (Jeff) Chen  %load_ext autotime %load_ext nb_black  import causalml import obp  &lt;script type=" />
<meta property="og:image"       content="https://jeffchenchengyi.github.io/_static/jeffchenchengyi2019.jpg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/jeffchenchengyi2019.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ΨΦ</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Notes
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ml-ifaqs.html">
   Infrequently Asked Questions in ML
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Uplift Modelling and Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="probabilistic-machine-learning/00-objective.html">
   Probabilistic Machine Learning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="probabilistic-machine-learning/01-frequentist-bayesian.html">
     Frequentist Vs. Bayesian Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="probabilistic-machine-learning/02-finding-the-posterior.html">
     Finding the Posterior of Latent Variables
     <span class="math notranslate nohighlight">
      \(\mathcal{Z}\)
     </span>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Personal Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../projects/bayesian-contextual-bandits.html">
   Bayesian Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../projects/wtte-rnn-pyro.html">
   Weibull Time To Event Recurrent Neural Net in Pyro
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Featured Course Work &amp; Extra-curriculars
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-562/intro.html">
   ISE-562 Decision Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-562/lab_assignment.html">
     Certain Equivalents and Sensitivity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-562/midterm.html">
     Mid Term Part (2): Individual Assignment: Tornado Diagrams and Bidding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-533/intro.html">
   ISE-533 Integrative Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/project1.html">
     Project 1: Group Restaurants Choice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/project2.html">
     Project 2: Multi-location Transshipment Problem
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-537/intro.html">
   ISE-537 Financial Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw2_part1.html">
     HW 2 Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw2_part2.html">
     HW 2 Part 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/ise-537/market-observations.html">
     Market Observations
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-1.html">
       MO 1: TSLA Absurd P/E Ratio
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-2.html">
       MO 2: The NASDAQ Whale
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-3.html">
       MO 4: Dovish till 2024
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-4.html">
       MO 4: The Future of EV batteries
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-5.html">
       MO 5: Palantir
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/ise-537/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-1.html">
       Paper Review 1: Value and Momentum Everywhere
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-2.html">
       Paper Review 2: Carry
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-3.html">
       Paper Review 3: Quality Minus Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-4.html">
       Paper Review 4: Size Matters, if You Control Your Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-5.html">
       Paper Review 5: The Low-Risk Anomaly: A Decomposition into Micro and Macro Effects
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/project1.html">
     Project 1: Momentum Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/project2.html">
     Project 2: Carry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/notes.html">
     Notes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-530/intro.html">
   ISE-530 Optimization Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw4.html">
     HW 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw5.html">
     HW 5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw6.html">
     HW 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw7.html">
     HW 7
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw8.html">
     HW 8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw9.html">
     HW 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/midterm.html">
     Midterm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/final.html">
     Final
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/notes.html">
     Summary
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/csci-499/intro.html">
   CSCI-499 AI for Social Good
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/csci-499/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-1.html">
       Paper Review 1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-2.html">
       Paper Review 2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-3.html">
       Paper Review 3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-4.html">
       Paper Review 4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-5.html">
       Paper Review 5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-6.html">
       Paper Review 6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-7.html">
       Paper Review 7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-8.html">
       Paper Review 8
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://docs.google.com/presentation/d/1MqA1jPrUw2UUTnQBGHqH-_Y3FCcOgsUGoCG1LNnCvZY/edit?usp=sharing">
     Paper Review Presentation
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/lucashu1/education-deserts">
     Education Deserts Research
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/cais%2B%2B/intro.html">
   CAIS++
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/pelillian/varro">
     Evolving FPGAs for Accelerated MachineLearning on Bare Metal
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/usc-caisplusplus/SLAB">
     OCR Research on Google Street View Panoramics
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../course-work/udacity/exploring-house-prices-singapore-part-3-crispdm.html">
   Udacity Data Scientist Nanodegree - Exploring House Prices in Singapore
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://graduation.udacity.com/confirm/2LGCCKNA">
   Udacity Data Scientist Nanodegree Certificate
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/13GaYnn520MGQtO4PfYjP4W6KFqyyI10T/view?usp=sharing">
   Chengyi (Jeff) Chen's Resume
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notes/uplift-modelling-and-contextual-bandits.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preliminaries">
   Preliminaries
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-uplift-modelling">
     What is uplift modelling?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-contextual-bandits">
     What are contextual bandits?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-armed-bandit">
       1. Multi-armed Bandit
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#contextual-bandit">
       2. Contextual Bandit
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#full-reinforcement-learning">
       3. Full Reinforcement Learning
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#off-policy-confidence-intervals">
   15.2. Off-Policy Confidence Intervals
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#t-distribution-population-variance-unknown">
     15.2.1 T-distribution (Population Variance Unknown)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#asymptotically-gaussian-central-limit-theorem">
     15.2.2 Asymptotically Gaussian (Central Limit Theorem)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clopper-pearson">
     15.2.3 Clopper-Pearson
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrapping">
     15.2.4 Bootstrapping
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concentration-inequality-hoeffding-inequality">
     15.2.5 Concentration Inequality: Hoeffding Inequality
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concentration-inequality-bernstein-inequality">
     15.2.6 Concentration Inequality: Bernstein Inequality
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-learning-context-free">
   15.3. Online Learning: Context-free
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random">
     15.3.1 Random
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#epsilon-greedy">
     15.3.2 Epsilon Greedy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bernoulli-thompson-sampling">
     15.3.3 Bernoulli Thompson Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-learning-contextual-linear">
   15.4. Online Learning: Contextual (Linear)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-epsilon-greedy">
     15.4.1 Linear Epsilon Greedy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-thompson-sampling">
     15.4.2 Linear Thompson Sampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-upper-confidence-bound">
     15.4.3 Linear Upper Confidence Bound
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-learning-contextual-logistic">
   15.5. Online Learning: Contextual (Logistic)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-epsilon-greedy">
     15.5.1 Logistic Epsilon Greedy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-thompson-sampling">
     15.5.2 Logistic Thompson Sampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-upper-confidence-bound">
     15.5.3 Logistic Upper Confidence Bound
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#offline-off-policy-learning-algorithms">
   15.6. Offline (Off-Policy) Learning Algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inverse-probability-weighting-ipw-learner">
     15.6.1 Inverse Probability Weighting (IPW) Learner
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="uplift-modelling-and-contextual-bandits-in-progress">
<h1>Uplift Modelling and Contextual Bandits [In Progress]<a class="headerlink" href="#uplift-modelling-and-contextual-bandits-in-progress" title="Permalink to this headline">¶</a></h1>
<p>By: Chengyi (Jeff) Chen</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autotime
<span class="o">%</span><span class="k">load_ext</span> nb_black

<span class="kn">import</span> <span class="nn">causalml</span>
<span class="kn">import</span> <span class="nn">obp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">
            setTimeout(function() {
                var nbb_cell_id = 3;
                var nbb_unformatted_code = "%load_ext autotime\n%load_ext nb_black\n\nimport causalml\nimport obp";
                var nbb_formatted_code = "%load_ext autotime\n%load_ext nb_black\n\nimport causalml\nimport obp";
                var nbb_cells = Jupyter.notebook.get_cells();
                for (var i = 0; i < nbb_cells.length; ++i) {
                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {
                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {
                             nbb_cells[i].set_text(nbb_formatted_code);
                        }
                        break;
                    }
                }
            }, 500);
            </script></div>
</div>
<hr class="docutils" />
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Having worked with uplift modelling at Shopee and contextual bandits at Gojek, I’ve come to realize huge similarities between the way these two seemingly disparate problems are modelled. In the following post, I’ll do my best to reconcile the relationship between these two modelling approaches and show how uplift modelling is simply a subclass of contextual bandits. I’ll be going through uplift modelling with the help of Uber’s <a class="reference external" href="https://causalml.readthedocs.io/en/latest/index.html">Causal ML</a> package and contextual bandits with <a class="reference external" href="https://zr-obp.readthedocs.io/en/latest/index.html">Open Bandit Pipeline</a>. In particular, I’m interested in comparing the different algorithms used for off-policy evaluation</p>
</div>
<hr class="docutils" />
<div class="section" id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h2>
<div class="section" id="what-is-uplift-modelling">
<h3>What is uplift modelling?<a class="headerlink" href="#what-is-uplift-modelling" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="what-are-contextual-bandits">
<h3>What are contextual bandits?<a class="headerlink" href="#what-are-contextual-bandits" title="Permalink to this headline">¶</a></h3>
<div class="section" id="multi-armed-bandit">
<h4>1. <a class="reference external" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed Bandit</a><a class="headerlink" href="#multi-armed-bandit" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="contextual-bandit">
<h4>2. Contextual Bandit<a class="headerlink" href="#contextual-bandit" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="full-reinforcement-learning">
<h4>3. Full Reinforcement Learning<a class="headerlink" href="#full-reinforcement-learning" title="Permalink to this headline">¶</a></h4>
<p>https://stats.stackexchange.com/questions/89396/multi-armed-bandit-algorithms-vs-uplift-modeling</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="off-policy-confidence-intervals">
<h2>15.2. Off-Policy Confidence Intervals<a class="headerlink" href="#off-policy-confidence-intervals" title="Permalink to this headline">¶</a></h2>
<div class="section" id="t-distribution-population-variance-unknown">
<h3>15.2.1 T-distribution (Population Variance Unknown)<a class="headerlink" href="#t-distribution-population-variance-unknown" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">student_t_bound</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the Student T&#39;s confidence interval for the V_ips estimator</span>
<span class="sd">    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n</span>

<span class="sd">    Args:</span>
<span class="sd">        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator</span>
<span class="sd">        var_V_ips (float): Variance of V_ips</span>
<span class="sd">        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy&#39;s probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)</span>
<span class="sd">        n (int): Size of the logging policy dataset</span>
<span class="sd">        δ (float): Significance level for confidence coverage. If δ = 0.05, it&#39;s a 95% confidence interval</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple: (lower bound of V(π), upper bound of V(π))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">t_score</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_score</span><span class="o">*</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;var_V_ips&quot;</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)))</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_score</span><span class="o">*</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;var_V_ips&quot;</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)))</span>

    <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="asymptotically-gaussian-central-limit-theorem">
<h3>15.2.2 Asymptotically Gaussian (Central Limit Theorem)<a class="headerlink" href="#asymptotically-gaussian-central-limit-theorem" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">asymptotic_gaussian_bound</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the asymptotically Gaussian confidence interval for the V_ips estimator</span>
<span class="sd">    As n --&gt; \infty, by CLT, sampling distribution of the sample mean of the random variable,</span>
<span class="sd">    in our case: importance-weighted rewards are our random variable α.</span>
<span class="sd">    If V_ips = 1/nΣ_nX = μ, then var[V_ips] = sample variance / n = (1/(n - 1)Σ_n(X - μ)^2) / n</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator</span>
<span class="sd">        var_V_ips (float): Variance of V_ips</span>
<span class="sd">        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy&#39;s probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)</span>
<span class="sd">        n (int): Size of the logging policy dataset</span>
<span class="sd">        δ (float): Significance level for confidence coverage. If δ = 0.05, it&#39;s a 95% confidence interval</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple: (lower bound of V(π), upper bound of V(π))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z_score</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">z_score</span><span class="o">*</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;var_V_ips&quot;</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)))</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">z_score</span><span class="o">*</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;var_V_ips&quot;</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)))</span>

    <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="clopper-pearson">
<h3>15.2.3 Clopper-Pearson<a class="headerlink" href="#clopper-pearson" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clopper_pearson_bound</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the clopper pearson bound for the V_ips estimator</span>
<span class="sd">    0 &lt;= V(π) &lt;= 1</span>
<span class="sd">    https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval</span>

<span class="sd">    Args:</span>
<span class="sd">        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator</span>
<span class="sd">        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy&#39;s probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)</span>
<span class="sd">        n (int): Size of the logging policy dataset</span>
<span class="sd">        δ (float): Significance level for confidence coverage. If δ = 0.05, it&#39;s a 95% confidence interval</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple: (lower clopper-pearson bound of V(π), upper clopper-pearson bound of V(π))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;w_max&quot;</span><span class="p">]</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">betaincinv</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">betaincinv</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">k</span> <span class="k">else</span> <span class="mi">1</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;w_max&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">lb</span><span class="p">))</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;w_max&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">ub</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bootstrapping">
<h3>15.2.4 Bootstrapping<a class="headerlink" href="#bootstrapping" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="concentration-inequality-hoeffding-inequality">
<h3>15.2.5 Concentration Inequality: Hoeffding Inequality<a class="headerlink" href="#concentration-inequality-hoeffding-inequality" title="Permalink to this headline">¶</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-1c8ab3c9-39ed-4caf-aa47-8270f744d7f1">
<span class="eqno">(2)<a class="headerlink" href="#equation-1c8ab3c9-39ed-4caf-aa47-8270f744d7f1" title="Permalink to this equation">¶</a></span>\[\begin{align}
    {
        \left\vert
            \hat{V}_{\text{IPS}}{(\pi)} 
            - {V}(\pi)
        \right\vert
    } 
    &amp;\leq 
    \sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}} \\
\end{align}\]</div>
<p>Hoeffding’s Inequality: Let <span class="math notranslate nohighlight">\(X_1, ..., X_n\)</span> be independent random variables strictly bounded by the interval <span class="math notranslate nohighlight">\([a_i, b_i]\)</span>, <span class="math notranslate nohighlight">\(a_i \leq X_i \leq b_i\)</span>. We define the empirical mean of these variables by <span class="math notranslate nohighlight">\(\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i\)</span>, such that</p>
<div class="amsmath math notranslate nohighlight" id="equation-bd090f4d-33a0-4d0d-8fee-fb3414929056">
<span class="eqno">(3)<a class="headerlink" href="#equation-bd090f4d-33a0-4d0d-8fee-fb3414929056" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(\left\vert \bar{X} - \mathbb{E}[\bar{X}] \right\vert \geq \epsilon) \leq 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)} \\
\end{align}\]</div>
<p>From Hoeffding’s Inequality:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b08d68f1-8f22-4535-9dde-f6bfd0abfafe">
<span class="eqno">(4)<a class="headerlink" href="#equation-b08d68f1-8f22-4535-9dde-f6bfd0abfafe" title="Permalink to this equation">¶</a></span>\[\begin{align}
P(\left\vert \bar{X} - \mathbb{E}[\bar{X}] \right\vert \geq \epsilon) &amp;\leq 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)} \\
1 - P(\left\vert \bar{X} - \mathbb{E}[\bar{X}] \right\vert &lt; \epsilon) &amp;\leq 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)} \\
\end{align}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-50d9975e-2e52-4835-a6f7-77ec1434515f">
<span class="eqno">(5)<a class="headerlink" href="#equation-50d9975e-2e52-4835-a6f7-77ec1434515f" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\label{eq:1}
P(\left\vert \bar{X} - \mathbb{E}[\bar{X}] \right\vert &lt; \epsilon) \geq \underbrace{1 - 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)}}_{1-\delta}
\end{equation}\]</div>
<p>Finding <span class="math notranslate nohighlight">\(\epsilon\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a35a47be-b7db-473c-8473-f2c478a92369">
<span class="eqno">(6)<a class="headerlink" href="#equation-a35a47be-b7db-473c-8473-f2c478a92369" title="Permalink to this equation">¶</a></span>\[\begin{align}
\therefore 1-\delta &amp;= 1 - 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)} \\
\delta &amp;= 2{e}^{\Big(-\frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2}\Big)} \\
\ln{\delta} &amp;= \ln{2} - \frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2} \\
\ln{\frac{2}{\delta}} &amp;= \frac{2n^2\epsilon^2}{\sum_{i=1}^{n}{(b_i - a_i)}^2} \\
2n^2\epsilon^2 &amp;= \sum_{i=1}^{n}{(b_i - a_i)}^2 \ln{\frac{2}{\delta}} \\
\epsilon &amp;= \sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}} \\
\end{align}\]</div>
<p>Substituting <span class="math notranslate nohighlight">\(\epsilon\)</span> into Equation 1, we get our Hoeffding Bound Confidence Intervals:</p>
<div class="amsmath math notranslate nohighlight" id="equation-092ebe7e-469e-473e-9606-633f6af4c6cd">
<span class="eqno">(7)<a class="headerlink" href="#equation-092ebe7e-469e-473e-9606-633f6af4c6cd" title="Permalink to this equation">¶</a></span>\[\begin{align}
P\Bigg(\left\vert \bar{X} - \mathbb{E}[\bar{X}] \right\vert &lt; \sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta \\
P\Bigg(-\sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}}&lt; \bar{X} - \mathbb{E}[\bar{X}] &lt; \sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta \\
P\Bigg(\bar{X}-\sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}}&lt; \mathbb{E}[\bar{X}] &lt; \bar{X}+\sqrt{\frac{\sum_{i=1}^{n}{(b_i - a_i)}^2}{2n^2} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta
\end{align}\]</div>
<p>Assuming that propensity scores <span class="math notranslate nohighlight">\(\alpha_i\)</span> are bounded between <span class="math notranslate nohighlight">\([0, w_{max}=\text{max}_{i\in n}\frac{\pi(a_i\vert x_i)}{\mu(a_i\vert x_i)}r_i]\)</span>, we can substitute the following:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}]: V(\pi)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(X_i: \alpha_i = \frac{\pi(a_i\vert x_i)}{\mu(a_i\vert x_i}r_i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{X}: \hat{V_{\text{IPS}}}(\pi) = \frac{1}{n} \sum_{i=1}^{n}\frac{\pi(a_i\vert x_i)}{\mu(a_i\vert x_i)}r_i\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(b_i: w_{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(a_i: 0\)</span></p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-2219d7b7-2758-4bea-9f6d-6ad52b37c718">
<span class="eqno">(8)<a class="headerlink" href="#equation-2219d7b7-2758-4bea-9f6d-6ad52b37c718" title="Permalink to this equation">¶</a></span>\[\begin{align}
P\Bigg(\hat{V_{\text{IPS}}}(\pi)-\sqrt{\frac{\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \ln{\frac{2}{\delta}}} &lt; V(\pi) &lt; \hat{V_{\text{IPS}}}(\pi)+\sqrt{\frac{\sum_{i=1}^{n}{(w_{max} - 0)}^2}{2n^2} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta \\
P\Bigg(\hat{V_{\text{IPS}}}(\pi)-\sqrt{\frac{nw^2_{max}}{2n^2} \ln{\frac{2}{\delta}}} &lt; V(\pi) &lt; \hat{V_{\text{IPS}}}(\pi)+\sqrt{\frac{nw^2_{max}}{2n^2} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta \\
P\Bigg(\hat{V_{\text{IPS}}}(\pi)-w_{max}\sqrt{\frac{1}{2n} \ln{\frac{2}{\delta}}} &lt; V(\pi) &lt; \hat{V_{\text{IPS}}}(\pi)+w_{max}\sqrt{\frac{1}{2n} \ln{\frac{2}{\delta}}}\Bigg) &amp;\geq 1-\delta
\end{align}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hoeffding_bound</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the empirical hoeffding bounds for the V_ips estimator</span>
<span class="sd">    using the Hoeffding Inequality</span>

<span class="sd">    Args:</span>
<span class="sd">        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator</span>
<span class="sd">        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy&#39;s probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)</span>
<span class="sd">        n (int): Size of the logging policy dataset</span>
<span class="sd">        δ (float): Significance level for confidence coverage. Default = 0.05, meaning a 95% confidence interval</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple: (lower empirical hoeffding bound of V(π), upper empirical hoeffding bound of V(π))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ε</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;w_max&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">]))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">]))</span>
    <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">ε</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">ε</span>
    <span class="k">return</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="concentration-inequality-bernstein-inequality">
<h3>15.2.6 Concentration Inequality: Bernstein Inequality<a class="headerlink" href="#concentration-inequality-bernstein-inequality" title="Permalink to this headline">¶</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-05c1fc91-5253-4446-858a-bfae1f99915d">
<span class="eqno">(9)<a class="headerlink" href="#equation-05c1fc91-5253-4446-858a-bfae1f99915d" title="Permalink to this equation">¶</a></span>\[\begin{align}
    {
        \left\vert
            \hat{V}_{\text{IPS}}{(\pi)} 
            - {V}(\pi)
        \right\vert
    } 
    &amp;\leq 
    {
        \sqrt{
            {2\text{log}\frac{2}{\delta}}{\frac{{\text{Var}}_{(x, a, r) \sim \mu}[\hat{V}_{\text{IPS}}{(\pi)}]}{n}}} 
        + \frac{2{\hat{w}_{max}}}{3n}{\text{log} \frac{2}{\delta}}
    } \\
\end{align}\]</div>
<p>Bernstein Inequality: Suppose <span class="math notranslate nohighlight">\(X_1, \cdots, X_n\)</span> are <span class="math notranslate nohighlight">\(i.i.d.\)</span> with 0 mean, variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\vert X_i \vert \leq M\)</span> almost surely,</p>
<div class="amsmath math notranslate nohighlight" id="equation-fe480f04-6958-4e75-b502-9b33a6bfef24">
<span class="eqno">(10)<a class="headerlink" href="#equation-fe480f04-6958-4e75-b502-9b33a6bfef24" title="Permalink to this equation">¶</a></span>\[\begin{align}
    P\Bigg({
        \left\vert
            \frac{1}{n}\sum^{n}_{i=1} X_i
        \right\vert
    } 
    &amp;\leq 
    {
        \sqrt{\frac{2\sigma^2}{n}\log\frac{2}{\delta}} 
        + \frac{2M}{3n}{\log\frac{2}{\delta}}
    }\Bigg) \geq 1 - \delta
\end{align}\]</div>
<p>Since <span class="math notranslate nohighlight">\(V_{\text{IPS}}(\pi)\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(V(\pi)\)</span>, <span class="math notranslate nohighlight">\(\hat{V}_{\text{IPS}}{(\pi)} - {V}(\pi)\)</span> has 0 mean, and variance of <span class="math notranslate nohighlight">\(Var[\hat{V}_{\text{IPS}}(\pi)]\)</span>, and setting <span class="math notranslate nohighlight">\(M: w_{max}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-859ac7f9-4b81-4280-819c-a5e28f4f2224">
<span class="eqno">(11)<a class="headerlink" href="#equation-859ac7f9-4b81-4280-819c-a5e28f4f2224" title="Permalink to this equation">¶</a></span>\[\begin{align}
    P\Bigg({
        \left\vert
            \hat{V}_{\text{IPS}}{(\pi)} 
            - {V}(\pi)
        \right\vert
    } 
    &amp;\leq 
    {
        \sqrt{
            {2\text{log}\frac{2}{\delta}}{\frac{{\text{Var}}_{(x, a, r) \sim \mu}[\hat{V}_{\text{IPS}}{(\pi)}]}{n}}} 
        + \frac{2{\hat{w}_{max}}}{3n}{\text{log} \frac{2}{\delta}}
    }\Bigg) \geq 1-\delta
\end{align}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-5642d89e-e28d-4fe7-b7e8-9b8125ae7065">
<span class="eqno">(12)<a class="headerlink" href="#equation-5642d89e-e28d-4fe7-b7e8-9b8125ae7065" title="Permalink to this equation">¶</a></span>\[\begin{align}
    P\Bigg(\hat{V}_{\text{IPS}}{(\pi)} 
    -
    \Bigg({
        \sqrt{
            {2\text{log}\frac{2}{\delta}}{\frac{{\text{Var}}_{(x, a, r) \sim \mu}[\hat{V}_{\text{IPS}}{(\pi)}]}{n}}} 
        + \frac{2{\hat{w}_{max}}}{3n}{\text{log} \frac{2}{\delta}}
    }\Bigg)
    &amp;\leq
    {V}(\pi)
    \leq
    \hat{V}_{\text{IPS}}{(\pi)}
    +
    \Bigg({
        \sqrt{
            {2\text{log}\frac{2}{\delta}}{\frac{{\text{Var}}_{(x, a, r) \sim \mu}[\hat{V}_{\text{IPS}}{(\pi)}]}{n}}} 
        + \frac{2{\hat{w}_{max}}}{3n}{\text{log} \frac{2}{\delta}}
    }\Bigg
    )
    \Bigg) &amp;\geq 1 - \delta \\
\end{align}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bernstein_bound</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the empirical benrstein bounds for the V_ips estimator</span>
<span class="sd">    using the Bernstein Inequality</span>

<span class="sd">    Args:</span>
<span class="sd">        V_ips (float): Estimated value of the policy π using the Inverse Propensity Score estimator</span>
<span class="sd">        var_V_ips (float): Variance of V_ips</span>
<span class="sd">        w_max (float): Largest Ratio of current policy probability of taking logging policy action a_i given context x_i to logging policy&#39;s probability of taking action a_i given context x_i - π(a_i|x_i) / μ(a_i | x_i)</span>
<span class="sd">        n (int): Size of the logging policy dataset</span>
<span class="sd">        δ (float): Significance level for confidence coverage. If δ = 0.05, it&#39;s a 95% confidence interval</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple: (lower empirical bernstein bound of V(π), upper empirical bernstein bound of V(π))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ε</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;var_V_ips&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;w_max&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;δ&quot;</span><span class="p">])</span>
    <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n&quot;</span><span class="p">])</span>

    <span class="c1"># ε = np.sqrt(</span>
    <span class="c1">#     2 * np.log(2 / kwargs[&quot;δ&quot;]) * (kwargs[&quot;var_V_ips&quot;] / kwargs[&quot;n&quot;])</span>
    <span class="c1"># ) + (2 * kwargs[&quot;w_max&quot;] * np.log(2 / kwargs[&quot;δ&quot;])) / (3 * kwargs[&quot;n&quot;])</span>

    <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">ε</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;V_ips&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">ε</span>
    <span class="k">return</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="online-learning-context-free">
<h2>15.3. Online Learning: Context-free<a class="headerlink" href="#online-learning-context-free" title="Permalink to this headline">¶</a></h2>
<div class="section" id="random">
<h3>15.3.1 Random<a class="headerlink" href="#random" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="epsilon-greedy">
<h3>15.3.2 Epsilon Greedy<a class="headerlink" href="#epsilon-greedy" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="bernoulli-thompson-sampling">
<h3>15.3.3 Bernoulli Thompson Sampling<a class="headerlink" href="#bernoulli-thompson-sampling" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<hr class="docutils" />
<div class="section" id="online-learning-contextual-linear">
<h2>15.4. Online Learning: Contextual (Linear)<a class="headerlink" href="#online-learning-contextual-linear" title="Permalink to this headline">¶</a></h2>
<div class="section" id="linear-epsilon-greedy">
<h3>15.4.1 Linear Epsilon Greedy<a class="headerlink" href="#linear-epsilon-greedy" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="linear-thompson-sampling">
<h3>15.4.2 Linear Thompson Sampling<a class="headerlink" href="#linear-thompson-sampling" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="linear-upper-confidence-bound">
<h3>15.4.3 Linear Upper Confidence Bound<a class="headerlink" href="#linear-upper-confidence-bound" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<hr class="docutils" />
<div class="section" id="online-learning-contextual-logistic">
<h2>15.5. Online Learning: Contextual (Logistic)<a class="headerlink" href="#online-learning-contextual-logistic" title="Permalink to this headline">¶</a></h2>
<div class="section" id="logistic-epsilon-greedy">
<h3>15.5.1 Logistic Epsilon Greedy<a class="headerlink" href="#logistic-epsilon-greedy" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="logistic-thompson-sampling">
<h3>15.5.2 Logistic Thompson Sampling<a class="headerlink" href="#logistic-thompson-sampling" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="logistic-upper-confidence-bound">
<h3>15.5.3 Logistic Upper Confidence Bound<a class="headerlink" href="#logistic-upper-confidence-bound" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<hr class="docutils" />
<div class="section" id="offline-off-policy-learning-algorithms">
<h2>15.6. Offline (Off-Policy) Learning Algorithms<a class="headerlink" href="#offline-off-policy-learning-algorithms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="inverse-probability-weighting-ipw-learner">
<h3>15.6.1 Inverse Probability Weighting (IPW) Learner<a class="headerlink" href="#inverse-probability-weighting-ipw-learner" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-ml-py"
        },
        kernelOptions: {
            kernelName: "conda-env-ml-py",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-ml-py'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ml-ifaqs.html" title="previous page">Machine Learning <em>In</em>Frequently Asked Questions</a>
    <a class='right-next' id="next-link" href="probabilistic-machine-learning/00-objective.html" title="next page">Probabilistic Machine Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chengyi (Jeff) Chen<br/>
        
            &copy; Copyright 2022.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>