
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Frequentist Vs. Bayesian Methods &#8212; ΨΦ</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jeffchenchengyi.github.io/notes/probabilistic-machine-learning/01-frequentist-bayesian.html" />
    <link rel="shortcut icon" href="../../_static/jeffchenchengyi2019.jpg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Finding the Posterior of Latent Variables \(\mathcal{Z}\)" href="02-finding-the-posterior.html" />
    <link rel="prev" title="Probabilistic Machine Learning" href="00-objective.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://jeffchenchengyi.github.io/notes/probabilistic-machine-learning/01-frequentist-bayesian.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Frequentist Vs. Bayesian Methods" />
<meta property="og:description" content="Frequentist Vs. Bayesian Methods  By: Chengyi (Jeff) Chen    Introduction    Maximum Likelihood Estimation  Derivation 1: KL Divergence  How to find the best p(" />
<meta property="og:image"       content="https://jeffchenchengyi.github.io/_static/jeffchenchengyi2019.jpg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/jeffchenchengyi2019.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ΨΦ</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Notes
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-ifaqs.html">
   Infrequently Asked Questions in ML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../uplift-modelling-and-contextual-bandits.html">
   Uplift Modelling and Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="00-objective.html">
   Probabilistic Machine Learning
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Frequentist Vs. Bayesian Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02-finding-the-posterior.html">
     Finding the Posterior of Latent Variables
     <span class="math notranslate nohighlight">
      \(\mathcal{Z}\)
     </span>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Personal Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../projects/bayesian-contextual-bandits.html">
   Bayesian Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../projects/wtte-rnn-pyro.html">
   Weibull Time To Event Recurrent Neural Net in Pyro
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Featured Course Work &amp; Extra-curriculars
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/ise-562/intro.html">
   ISE-562 Decision Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-562/lab_assignment.html">
     Certain Equivalents and Sensitivity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-562/midterm.html">
     Mid Term Part (2): Individual Assignment: Tornado Diagrams and Bidding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/ise-533/intro.html">
   ISE-533 Integrative Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-533/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-533/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-533/project1.html">
     Project 1: Group Restaurants Choice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-533/project2.html">
     Project 2: Multi-location Transshipment Problem
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/ise-537/intro.html">
   ISE-537 Financial Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/hw2_part1.html">
     HW 2 Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/hw2_part2.html">
     HW 2 Part 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../course-work/ise-537/market-observations.html">
     Market Observations
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/market-observations-week-1.html">
       MO 1: TSLA Absurd P/E Ratio
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/market-observations-week-2.html">
       MO 2: The NASDAQ Whale
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/market-observations-week-3.html">
       MO 4: Dovish till 2024
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/market-observations-week-4.html">
       MO 4: The Future of EV batteries
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/market-observations-week-5.html">
       MO 5: Palantir
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../course-work/ise-537/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/paper-review-1.html">
       Paper Review 1: Value and Momentum Everywhere
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/paper-review-2.html">
       Paper Review 2: Carry
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/paper-review-3.html">
       Paper Review 3: Quality Minus Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/paper-review-4.html">
       Paper Review 4: Size Matters, if You Control Your Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/ise-537/paper-review-5.html">
       Paper Review 5: The Low-Risk Anomaly: A Decomposition into Micro and Macro Effects
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/project1.html">
     Project 1: Momentum Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/project2.html">
     Project 2: Carry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-537/notes.html">
     Notes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/ise-530/intro.html">
   ISE-530 Optimization Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw4.html">
     HW 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw5.html">
     HW 5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw6.html">
     HW 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw7.html">
     HW 7
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw8.html">
     HW 8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/hw9.html">
     HW 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/midterm.html">
     Midterm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/final.html">
     Final
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../course-work/ise-530/notes.html">
     Summary
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/csci-499/intro.html">
   CSCI-499 AI for Social Good
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../course-work/csci-499/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-1.html">
       Paper Review 1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-2.html">
       Paper Review 2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-3.html">
       Paper Review 3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-4.html">
       Paper Review 4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-5.html">
       Paper Review 5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-6.html">
       Paper Review 6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-7.html">
       Paper Review 7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../course-work/csci-499/paper-review-8.html">
       Paper Review 8
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://docs.google.com/presentation/d/1MqA1jPrUw2UUTnQBGHqH-_Y3FCcOgsUGoCG1LNnCvZY/edit?usp=sharing">
     Paper Review Presentation
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/lucashu1/education-deserts">
     Education Deserts Research
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../course-work/cais%2B%2B/intro.html">
   CAIS++
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/pelillian/varro">
     Evolving FPGAs for Accelerated MachineLearning on Bare Metal
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/usc-caisplusplus/SLAB">
     OCR Research on Google Street View Panoramics
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../course-work/udacity/exploring-house-prices-singapore-part-3-crispdm.html">
   Udacity Data Scientist Nanodegree - Exploring House Prices in Singapore
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://graduation.udacity.com/confirm/2LGCCKNA">
   Udacity Data Scientist Nanodegree Certificate
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/13GaYnn520MGQtO4PfYjP4W6KFqyyI10T/view?usp=sharing">
   Chengyi (Jeff) Chen's Resume
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notes/probabilistic-machine-learning/01-frequentist-bayesian.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-likelihood-estimation">
   Maximum Likelihood Estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivation-1-kl-divergence">
     Derivation 1: KL Divergence
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-find-the-best-p-mathcal-x-mathcal-z-theta-theta">
     How to find the best
     <span class="math notranslate nohighlight">
      \(p(\mathcal{X}, \mathcal{Z} ; \Theta = \theta)\)
     </span>
     ?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivation-2-posterior-with-uniform-prior-on-parameters">
     Derivation 2: Posterior with Uniform Prior on Parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-is-mle-a-frequentist-inference-technique">
     Why is MLE a “frequentist” inference technique?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#can-we-simply-find-the-theta-that-maximizes-p-mathcal-x-mathbf-x-text-train-theta-theta">
     Can we simply find the
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
     that maximizes
     <span class="math notranslate nohighlight">
      \(p(\mathcal{X}=\mathbf{X}_{\text{train}} ; \Theta = \theta)\)
     </span>
     ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-a-posteriori">
   Maximum A Posteriori
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivation-1-computationally-inconvienient-to-calculate-the-full-posterior-p-mathcal-theta-vert-mathcal-x-mathbf-x-text-train">
     Derivation 1: Computationally Inconvienient to calculate the full Posterior
     <span class="math notranslate nohighlight">
      \(p(\mathcal{\Theta} \vert \mathcal{X} = \mathbf{X}_{\text{train}})\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivation-2">
     Derivation 2:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-uncertainty">
     Parameter Uncertainty
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction-intervals">
     Prediction Intervals
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empircal-bayes-type-ii-maximum-likelihood-estimation">
   Empircal Bayes; Type II Maximum Likelihood Estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hierarchical-bayes">
   Hierarchical Bayes
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="frequentist-vs-bayesian-methods">
<h1>Frequentist Vs. Bayesian Methods<a class="headerlink" href="#frequentist-vs-bayesian-methods" title="Permalink to this headline">¶</a></h1>
<p>By: Chengyi (Jeff) Chen</p>
<hr class="docutils" />
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="maximum-likelihood-estimation">
<h2>Maximum Likelihood Estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="derivation-1-kl-divergence">
<h3>Derivation 1: KL Divergence<a class="headerlink" href="#derivation-1-kl-divergence" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="how-to-find-the-best-p-mathcal-x-mathcal-z-theta-theta">
<h3>How to find the best <span class="math notranslate nohighlight">\(p(\mathcal{X}, \mathcal{Z} ; \Theta = \theta)\)</span>?<a class="headerlink" href="#how-to-find-the-best-p-mathcal-x-mathcal-z-theta-theta" title="Permalink to this headline">¶</a></h3>
<p>To learn the <span class="math notranslate nohighlight">\(p(\mathcal{X}, \mathcal{Z} ; \Theta = \theta)\)</span>, we need to first design a <strong>measure of success</strong> – how useful our model is / how accurate are we modelling the real life true data distribution. Because we can only observe <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, let’s define a “distance” measure between our incomplete data likelihood <span class="math notranslate nohighlight">\(p(\mathcal{X} ; \Theta = \theta)\)</span> (instead of complete data likelihood because we can’t observe it) and the true data distribution <span class="math notranslate nohighlight">\(f(\mathcal{X})\)</span>. The smaller the “distance” between our 2 distributions the better our model approximates the true data generating process. A common “distance” measure between probability distributions is the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL Divergence</a> (“distance” because KL Divergence is asymmetric, does not satisfy triangle inequality, <span class="math notranslate nohighlight">\(D_{KL}(P \vert\vert Q) \not= D_{KL}(Q \vert\vert P)\)</span>). <span class="math notranslate nohighlight">\(D_{KL}(f(\mathcal{X}) \vert \vert p(\mathcal{X};\Theta=\theta))\)</span> measures how well <a class="reference external" href="https://stats.stackexchange.com/questions/111445/analysis-of-kullback-leibler-divergence"><span class="math notranslate nohighlight">\(p\)</span> approximates <span class="math notranslate nohighlight">\(f\)</span></a>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9ebee8cc-5638-4b25-8a30-31a17221c150">
<span class="eqno">(17)<a class="headerlink" href="#equation-9ebee8cc-5638-4b25-8a30-31a17221c150" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \theta^* 
    &amp;= \arg\underset{\theta \in \Theta}{\min} D_{KL}(f \vert \vert p) \\
    &amp;= \arg\underset{\theta \in \Theta}{\min}\int_{\mathbf{x} \in \mathcal{X}} f(\mathcal{X}=\mathbf{x}) \log \frac{f(\mathcal{X}=\mathbf{x})}{p(\mathcal{X}=\mathbf{x} ; \Theta = \theta)} d\mathbf{x} \\
    &amp;= \arg\underset{\theta \in \Theta}{\min}\mathbb{E}_{\mathbf{x} \sim f} [\log f(\mathcal{X}=\mathbf{x})] - \mathbb{E}_{\mathbf{x} \sim f} [\log p(\mathcal{X}=\mathbf{x} ; \Theta = \theta)] \\
    &amp;= \arg\underset{\theta \in \Theta}{\min}-\mathbb{H}[f(\mathcal{X})] - \mathbb{E}_{\mathbf{x} \sim f} [\log p(\mathcal{X}=\mathbf{x} ; \Theta = \theta)] \\
    &amp;= \arg\underset{\theta \in \Theta}{\max} \mathbb{E}_{\mathbf{x} \sim f} [\log p(\mathcal{X}=\mathbf{x} ; \Theta = \theta)] \\
    &amp;\approx \arg\underset{\theta \in \Theta}{\max} \lim_{N \rightarrow \infty} \frac{1}{N}\sum_{\mathbf{x}_i \in \mathbf{X}_{\text{train}}} \log p(\mathcal{X}=\mathbf{x}_i ; \Theta = \theta) \because \text{law of large numbers} \\
    &amp;= \arg\underset{\theta \in \Theta}{\max} \prod_{\mathbf{x}_i \in \mathbf{X}_{\text{train}}} p(\mathcal{X}=\mathbf{x}_i ; \Theta = \theta) \because \log\text{ is a monotonic increasing function} \\
    &amp;= \arg\underset{\theta \in \Theta}{\max} p(\mathcal{X}=\mathbf{X}_{\text{train}} ; \Theta = \theta) \because \text{i.i.d. data assumption} \\
    &amp;= \theta_{\text{MLE}}
\end{align}\]</div>
<p>We have thus arrived at <a class="reference external" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum Likelihood Estimation</a> of parameters (you can read more about this derivation method <a class="reference external" href="https://slideplayer.com/slide/9502040/">here</a> and <a class="reference external" href="https://jaketae.github.io/study/kl-mle/">here</a>), a pointwise estimate of the parameters that maximizes the incomplete data likelihood (or complete data likelihood when we have no latent variables in the model).</p>
</div>
<div class="section" id="derivation-2-posterior-with-uniform-prior-on-parameters">
<h3>Derivation 2: Posterior with Uniform Prior on Parameters<a class="headerlink" href="#derivation-2-posterior-with-uniform-prior-on-parameters" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="why-is-mle-a-frequentist-inference-technique">
<h3>Why is MLE a “frequentist” inference technique?<a class="headerlink" href="#why-is-mle-a-frequentist-inference-technique" title="Permalink to this headline">¶</a></h3>
<p>The primary reason for why this technique is coined a “frequentist” method is because of the assumption that <span class="math notranslate nohighlight">\(\Theta = \theta\)</span> is a fixed parameter that needs to be estimated, while bayesians believe that <span class="math notranslate nohighlight">\(\Theta = \theta\)</span> should be a random variable, and hence, have a probability distribution that describes its behavior <span class="math notranslate nohighlight">\(p(\Theta)\)</span>, calling it our <strong>prior</strong>. In probabilistic programming / machine learning however, we don’t have to worry about these conflicting paradigms. To “convert” <span class="math notranslate nohighlight">\(\Theta\)</span> into a random variable instead, we just need to move <span class="math notranslate nohighlight">\(\Theta\)</span> into <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> and as long as we have a way to model <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, more specifically <span class="math notranslate nohighlight">\(p(\mathcal{Z} \vert \mathcal{X} ; \Theta = \theta)\)</span>, the <strong>posterior</strong> distribution of our latent variables, we are good.</p>
</div>
<div class="section" id="can-we-simply-find-the-theta-that-maximizes-p-mathcal-x-mathbf-x-text-train-theta-theta">
<h3>Can we simply find the <span class="math notranslate nohighlight">\(\theta\)</span> that maximizes <span class="math notranslate nohighlight">\(p(\mathcal{X}=\mathbf{X}_{\text{train}} ; \Theta = \theta)\)</span>?<a class="headerlink" href="#can-we-simply-find-the-theta-that-maximizes-p-mathcal-x-mathbf-x-text-train-theta-theta" title="Permalink to this headline">¶</a></h3>
<p>Unfortunately, because our model is specified with the latent variables <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, we can’t directly maximize <span class="math notranslate nohighlight">\(p(\mathcal{X}=\mathbf{X}_{\text{train}} ; \Theta = \theta)\)</span>. We’ll have to marginalize out the latent variables first as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7ae5f107-f0f2-48a8-ad76-1252801237a8">
<span class="eqno">(18)<a class="headerlink" href="#equation-7ae5f107-f0f2-48a8-ad76-1252801237a8" title="Permalink to this equation">¶</a></span>\[\begin{align}
    p(\mathcal{X} = \mathbf{X}_{\text{train}} ; \Theta = \theta) 
    &amp;= \int_{\mathbf{z} \in \mathcal{Z}} p(\mathcal{X} = \mathbf{X}_{\text{train}}, \mathcal{Z} = \mathbf{z}; \Theta = \theta) d\mathbf{z} \\
    &amp;= \int_{\mathbf{z} \in \mathcal{Z}} p(\mathcal{X} = \mathbf{X}_{\text{train}} \vert \mathcal{Z} = \mathbf{z} ; \Theta = \theta) p(\mathcal{Z} = \mathbf{z} ; \Theta = \theta) d\mathbf{z} \\
\end{align}\]</div>
<p>and hence, Maximum Likelihood Estimation becomes:</p>
<div class="amsmath math notranslate nohighlight" id="equation-40cc9b30-0f07-4cdd-8baf-8e5994ed6b2a">
<span class="eqno">(19)<a class="headerlink" href="#equation-40cc9b30-0f07-4cdd-8baf-8e5994ed6b2a" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \theta^* 
    &amp;= \arg\underset{\theta \in \Theta}{\max} \int_{\mathbf{z} \in \mathcal{Z}} p(\mathcal{X} = \mathbf{X}_{\text{train}} \vert \mathcal{Z} = \mathbf{z} ; \Theta = \theta) p(\mathcal{Z} = \mathbf{z} ; \Theta = \theta) d\mathbf{z} \\
\end{align}\]</div>
<p>However, this marginalization is often intractable (e.g. if <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> is a sequence of events, so that the number of values grows exponentially with the sequence length, the exact calculation of the integral will be extremely difficult). Let’s instead try to find a lower bound for it by expanding it.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="maximum-a-posteriori">
<h2>Maximum A Posteriori<a class="headerlink" href="#maximum-a-posteriori" title="Permalink to this headline">¶</a></h2>
<div class="section" id="derivation-1-computationally-inconvienient-to-calculate-the-full-posterior-p-mathcal-theta-vert-mathcal-x-mathbf-x-text-train">
<h3>Derivation 1: Computationally Inconvienient to calculate the full Posterior <span class="math notranslate nohighlight">\(p(\mathcal{\Theta} \vert \mathcal{X} = \mathbf{X}_{\text{train}})\)</span><a class="headerlink" href="#derivation-1-computationally-inconvienient-to-calculate-the-full-posterior-p-mathcal-theta-vert-mathcal-x-mathbf-x-text-train" title="Permalink to this headline">¶</a></h3>
<p>Before continuing, realize that because</p>
<div class="amsmath math notranslate nohighlight" id="equation-42be26d6-c941-43bd-af1c-d8cb60321175">
<span class="eqno">(20)<a class="headerlink" href="#equation-42be26d6-c941-43bd-af1c-d8cb60321175" title="Permalink to this equation">¶</a></span>\[\begin{align}
    p(\mathcal{X}, \mathcal{Z} ; \Theta = \theta) &amp;= p(\mathcal{Z} \vert \mathcal{X}; \Theta = \theta) p(\mathcal{X} ; \Theta = \theta)
\end{align}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-f856fbc9-b19c-43d8-bda2-981212b0f683">
<span class="eqno">(21)<a class="headerlink" href="#equation-f856fbc9-b19c-43d8-bda2-981212b0f683" title="Permalink to this equation">¶</a></span>\[\begin{align}
    p(\mathcal{Z} \vert \mathcal{X}; \Theta = \theta) &amp;= \frac{}{}
\end{align}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-fba73ca7-e9c0-4885-9f6f-37189112e7a1">
<span class="eqno">(22)<a class="headerlink" href="#equation-fba73ca7-e9c0-4885-9f6f-37189112e7a1" title="Permalink to this equation">¶</a></span>\[\begin{align}
    &amp;= \arg\underset{\theta \in \Theta}{\max} \frac{1}{N}\sum_{\mathbf{x} \in \mathbf{x}_{\text{train}}} \int_{\mathbf{z} \in \mathcal{Z}} \log p(\mathcal{X}=\mathbf{x}, \mathcal{Z}=\mathbf{z}; \Theta = \theta) d\mathbf{z} \\
\end{align}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mathematical Notation</p>
<p>The math notation of my content, including the ones in this post follow the conventions in Christopher M. Bishop’s Pattern Recognition and Machine Learning. In addition, I use caligraphic capitalized roman and capitalized greek symbols like <span class="math notranslate nohighlight">\(\mathcal{X}, \mathcal{Y}, \mathcal{Z}, \Omega, \Psi, \Xi, \ldots\)</span> to represent <strong>BOTH</strong> a set of values that the random variables can take as well as the argument of a function in python (e.g. <code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">p(Θ=θ)</span></code>).</p>
</div>
<p>https://pyro.ai/examples/intro_long.html#Background:-inference,-learning-and-evaluation</p>
<p>Objective:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fcded3f3-8d31-45ca-9582-3790f14d997b">
<span class="eqno">(23)<a class="headerlink" href="#equation-fcded3f3-8d31-45ca-9582-3790f14d997b" title="Permalink to this equation">¶</a></span>\[\begin{align}
    
\end{align}\]</div>
</div>
<div class="section" id="derivation-2">
<h3>Derivation 2:<a class="headerlink" href="#derivation-2" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="parameter-uncertainty">
<h3>Parameter Uncertainty<a class="headerlink" href="#parameter-uncertainty" title="Permalink to this headline">¶</a></h3>
<p>Frequentist: Uncertainty is estimated with confidence intervals</p>
<p>Bayesian: Uncertainty is estimated with credible intervals</p>
</div>
<div class="section" id="prediction-intervals">
<h3>Prediction Intervals<a class="headerlink" href="#prediction-intervals" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<hr class="docutils" />
<div class="section" id="empircal-bayes-type-ii-maximum-likelihood-estimation">
<h2>Empircal Bayes; Type II Maximum Likelihood Estimation<a class="headerlink" href="#empircal-bayes-type-ii-maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="hierarchical-bayes">
<h2>Hierarchical Bayes<a class="headerlink" href="#hierarchical-bayes" title="Permalink to this headline">¶</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notes/probabilistic-machine-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="00-objective.html" title="previous page">Probabilistic Machine Learning</a>
    <a class='right-next' id="next-link" href="02-finding-the-posterior.html" title="next page">Finding the Posterior of Latent Variables <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span></a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chengyi (Jeff) Chen<br/>
        
            &copy; Copyright 2022.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>