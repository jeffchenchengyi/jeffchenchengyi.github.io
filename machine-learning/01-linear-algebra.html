
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Linear Algebra [In Progress] &#8212; ΨΦ</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jeffchenchengyi.github.io/machine-learning/01-linear-algebra.html" />
    <link rel="shortcut icon" href="../_static/jeffchenchengyi2019.jpg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Probability Distributions [Empty]" href="02-probability-distributions.html" />
    <link rel="prev" title="Machine Learning" href="00-intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://jeffchenchengyi.github.io/machine-learning/01-linear-algebra.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="1. Linear Algebra [In Progress]" />
<meta property="og:description" content="1. Linear Algebra [In Progress]    1.1    1.2. Eigenvalue Decomposition    1.3. Singular Value Decomposition    1.4. Symmetric Matrices  ```{tip} Theorem: X^\to" />
<meta property="og:image"       content="https://jeffchenchengyi.github.io/_static/jeffchenchengyi2019.jpg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/jeffchenchengyi2019.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ΨΦ</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="00-intro.html">
   Pattern Recognition and Machine Learning
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     1. Linear Algebra [In Progress]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02-probability-distributions.html">
     2. Probability Distributions [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03-linear-models-for-regression.html">
     3. Linear Models for Regression [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-linear-models-for-classification.html">
     4. Linear Models for Classification [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05-neural-networks.html">
     5. Neural Networks [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-kernel-methods.html">
     6. Kernel Methods [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07-sparse-kernel-machines.html">
     7. Sparse Kernel Machines [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-graphical-models.html">
     8. Graphical Models [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-mixture-models-and-em.html">
     9. Mixture Models and EM [In Progress]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10-approximate-inference.html">
     10. Approximate Inference [In Progress]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-sampling-methods.html">
     11. Sampling Methods [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-continuous-latent-variables.html">
     12. Continuous Latent Variables [In Progress]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-sequential-data.html">
     13. Sequential Data [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-combining-models.html">
     14. Combining Models [Empty]
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15-bandits.html">
     15. Bandits [In Progress]
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Personal Notes &amp; Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../personal-projects/notes/ml-ifaqs.html">
   Infrequently Asked Questions in ML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../personal-projects/notes/bayesian-machine-learning.html">
   Bayesian Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../personal-projects/notes/uplift-modelling-and-contextual-bandits.html">
   Uplift Modelling and Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../personal-projects/projects/bayesian-contextual-bandits.html">
   Bayesian Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../personal-projects/projects/wtte-rnn-pyro.html">
   Weibull Time To Event Recurrent Neural Net in Pyro
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Featured Course Work &amp; Extra-curriculars
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-562/intro.html">
   ISE-562 Decision Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-562/lab_assignment.html">
     Certain Equivalents and Sensitivity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-562/midterm.html">
     Mid Term Part (2): Individual Assignment: Tornado Diagrams and Bidding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-533/intro.html">
   ISE-533 Integrative Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/project1.html">
     Project 1: Group Restaurants Choice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-533/project2.html">
     Project 2: Multi-location Transshipment Problem
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-537/intro.html">
   ISE-537 Financial Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw2_part1.html">
     HW 2 Part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw2_part2.html">
     HW 2 Part 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/ise-537/market-observations.html">
     Market Observations
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-1.html">
       MO 1: TSLA Absurd P/E Ratio
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-2.html">
       MO 2: The NASDAQ Whale
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-3.html">
       MO 4: Dovish till 2024
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-4.html">
       MO 4: The Future of EV batteries
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/market-observations-week-5.html">
       MO 5: Palantir
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/ise-537/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-1.html">
       Paper Review 1: Value and Momentum Everywhere
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-2.html">
       Paper Review 2: Carry
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-3.html">
       Paper Review 3: Quality Minus Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-4.html">
       Paper Review 4: Size Matters, if You Control Your Junk
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/ise-537/paper-review-5.html">
       Paper Review 5: The Low-Risk Anomaly: A Decomposition into Micro and Macro Effects
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/project1.html">
     Project 1: Momentum Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/project2.html">
     Project 2: Carry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-537/notes.html">
     Notes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/ise-530/intro.html">
   ISE-530 Optimization Analytics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw1.html">
     HW 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw2.html">
     HW 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw3.html">
     HW 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw4.html">
     HW 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw5.html">
     HW 5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw6.html">
     HW 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw7.html">
     HW 7
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw8.html">
     HW 8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/hw9.html">
     HW 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/midterm.html">
     Midterm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/final.html">
     Final
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../course-work/ise-530/notes.html">
     Summary
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/csci-499/intro.html">
   CSCI-499 AI for Social Good
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../course-work/csci-499/paper-reviews.html">
     Paper Reviews
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-1.html">
       Paper Review 1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-2.html">
       Paper Review 2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-3.html">
       Paper Review 3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-4.html">
       Paper Review 4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-5.html">
       Paper Review 5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-6.html">
       Paper Review 6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-7.html">
       Paper Review 7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../course-work/csci-499/paper-review-8.html">
       Paper Review 8
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://docs.google.com/presentation/d/1MqA1jPrUw2UUTnQBGHqH-_Y3FCcOgsUGoCG1LNnCvZY/edit?usp=sharing">
     Paper Review Presentation
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/lucashu1/education-deserts">
     Education Deserts Research
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../course-work/cais%2B%2B/intro.html">
   CAIS++
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/pelillian/varro">
     Evolving FPGAs for Accelerated MachineLearning on Bare Metal
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/usc-caisplusplus/SLAB">
     OCR Research on Google Street View Panoramics
     <i class="fas fa-external-link-alt">
     </i>
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../course-work/udacity/exploring-house-prices-singapore-part-3-crispdm.html">
   Udacity Data Scientist Nanodegree - Exploring House Prices in Singapore
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://graduation.udacity.com/confirm/2LGCCKNA">
   Udacity Data Scientist Nanodegree Certificate
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/13GaYnn520MGQtO4PfYjP4W6KFqyyI10T/view?usp=sharing">
   Chengyi (Jeff) Chen's Resume
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io">
   GitHub Repo
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/machine-learning/01-linear-algebra.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jeffchenchengyi/jeffchenchengyi.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   1.1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eigenvalue-decomposition">
   1.2. Eigenvalue Decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#singular-value-decomposition">
   1.3. Singular Value Decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#symmetric-matrices">
   1.4. Symmetric Matrices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quadratic-form-minimization">
     1.4.1. Quadratic Form Minimization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projections">
   1.5. Projections
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#projections-onto-a-subspace-is-a-linear-transformation">
     1.5.1. Projections onto a subspace is a linear transformation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications-of-projections">
     1.5.2. Applications of Projections
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#geometric-interpretation-of-ordinary-least-squares-regression">
       1.5.2.1 Geometric Interpretation of Ordinary Least Squares Regression
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="linear-algebra-in-progress">
<h1>1. Linear Algebra [In Progress]<a class="headerlink" href="#linear-algebra-in-progress" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<div class="section" id="id1">
<h2>1.1<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="eigenvalue-decomposition">
<h2>1.2. Eigenvalue Decomposition<a class="headerlink" href="#eigenvalue-decomposition" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="singular-value-decomposition">
<h2>1.3. Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="symmetric-matrices">
<h2>1.4. Symmetric Matrices<a class="headerlink" href="#symmetric-matrices" title="Permalink to this headline">¶</a></h2>
<p>```{tip} Theorem: <span class="math notranslate nohighlight">\(X^\top X \succeq 0 \forall X\)</span> <a class="bibtex reference internal" href="#isb-bal41-online" id="id2">[2Is]</a></p>
<p>Is <span class="math notranslate nohighlight">\(X^\top X\)</span> always <span class="math notranslate nohighlight">\(\succeq 0\)</span>? Yes, and <span class="math notranslate nohighlight">\(X^\top X \succ 0\)</span> when <span class="math notranslate nohighlight">\(X\)</span> has linearly independent column vectors (invertible)</p>
<p>Proof:</p>
<p>Suppose <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{m \times n}\)</span> matrix and <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span> vector:</p>
<div class="amsmath math notranslate nohighlight" id="equation-2aec6b48-fbe8-445a-9266-4095ab6a810d">
<span class="eqno">(1)<a class="headerlink" href="#equation-2aec6b48-fbe8-445a-9266-4095ab6a810d" title="Permalink to this equation">¶</a></span>\[\begin{align}
    y^\top X^\top X y &amp;= {\left( \underbrace{Xy}_{z} \right)}^\top \underbrace{Xy}_{z} \\
    &amp;= z^\top z \begin{cases}
        &amp;= 0 \text{ if } y \in N(X) \left(y\text{ is in the nullspace of } X \right) \\
        &amp;&gt; 0 \text{ if } y \not\in N(X) \left(y\text{ is not in the nullspace of } X \right) \\
    \end{cases}
\end{align}\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>```{tip} Theorem: <span class="math notranslate nohighlight">\(X^\top A X \succeq 0 \forall X\)</span> <a class="bibtex reference internal" href="#forapos52-online" id="id3">[2Fo]</a></p>
<p>Is <span class="math notranslate nohighlight">\(X^\top A X\)</span> always <span class="math notranslate nohighlight">\(\succeq 0\)</span>? Given that <span class="math notranslate nohighlight">\(A \succ 0\)</span>, yes. <span class="math notranslate nohighlight">\(X^\top A X \succ 0\)</span> if <span class="math notranslate nohighlight">\(X\)</span> has linearly independent column vectors (invertible), and <span class="math notranslate nohighlight">\(X^\top A X \succeq 0\)</span> is <span class="math notranslate nohighlight">\(X\)</span> has linearly dependent column vectors.</p>
<p>Proof:</p>
<p>Suppose <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{m \times n}\)</span> matrix, <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times m} \succ 0\)</span> matrix, and <span class="math notranslate nohighlight">\(y \in \mathbb{R}^n\)</span> vector:</p>
<div class="amsmath math notranslate nohighlight" id="equation-91ab25a7-7c00-44eb-a58c-189458a14aed">
<span class="eqno">(2)<a class="headerlink" href="#equation-91ab25a7-7c00-44eb-a58c-189458a14aed" title="Permalink to this equation">¶</a></span>\[\begin{align}
    y^\top X^\top A X y &amp;= {\left( \underbrace{Xy}_{z} \right)}^\top A \underbrace{Xy}_{z} \\
    &amp;= z^\top A z \begin{cases}
        &amp;= 0 \text{ if } y \in N(X) \left(y\text{ is in the nullspace of } X \right) \\
        &amp;&gt; 0 \text{ if } y \not\in N(X) \left(y\text{ is not in the nullspace of } X \right) \\
    \end{cases}
\end{align}\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="section" id="quadratic-form-minimization">
<h3>1.4.1. Quadratic Form Minimization<a class="headerlink" href="#quadratic-form-minimization" title="Permalink to this headline">¶</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-8cfcf464-a44e-41e3-b262-7f64d88257ff">
<span class="eqno">(3)<a class="headerlink" href="#equation-8cfcf464-a44e-41e3-b262-7f64d88257ff" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \min
\end{align}\]</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="projections">
<h2>1.5. Projections<a class="headerlink" href="#projections" title="Permalink to this headline">¶</a></h2>
<p><span class="bibtex" id="id4">[Aproject8:online]</span></p>
<div class="section" id="projections-onto-a-subspace-is-a-linear-transformation">
<h3>1.5.1. Projections onto a subspace is a linear transformation<a class="headerlink" href="#projections-onto-a-subspace-is-a-linear-transformation" title="Permalink to this headline">¶</a></h3>
<p>Let <span class="math notranslate nohighlight">\(V\)</span> be a subspace in <span class="math notranslate nohighlight">\(\mathbb{R}^{n}\)</span></p>
<p>Let <span class="math notranslate nohighlight">\(B = \left\{\vec{b}_1, \vec{b}_2, \cdots, \vec{b}_k\right\}\)</span> is a basis for <span class="math notranslate nohighlight">\(V\)</span>, and <span class="math notranslate nohighlight">\(\therefore \forall \vec{a} \in V \Rightarrow \vec{a} = y_1\vec{b}_1 + y_2\vec{b}_2 + \cdots + y_k\vec{b}_k\)</span></p>
<p>Let <span class="math notranslate nohighlight">\(A\)</span> be the matrix of the basis vectors of <span class="math notranslate nohighlight">\(B\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-884d83d6-8f3d-4547-b1cf-ac2103a9e8e5">
<span class="eqno">(4)<a class="headerlink" href="#equation-884d83d6-8f3d-4547-b1cf-ac2103a9e8e5" title="Permalink to this equation">¶</a></span>\[\begin{align}
    A\vec{y} &amp;=
    \begin{bmatrix}
        \vert &amp; \vert &amp; &amp; \vert \\
        \vec{b}_1 &amp; \vec{b}_2 &amp; \cdots &amp; \vec{b}_k   \\
        \vert &amp; \vert &amp; &amp; \vert \\
    \end{bmatrix} 
    \begin{bmatrix}
        y_1 \\
        y_2 \\
        \vdots \\
        y_k \\
    \end{bmatrix}, \text{ for some } \vec{y} \in \mathbb{R}^{k} \\
    &amp;= y_1\vec{b}_1 + y_2\vec{b}_2 + \cdots + y_k\vec{b}_k \\
    &amp;= \vec{a}  \\
\end{align}\]</div>
<p>A projection of an arbitrary vector <span class="math notranslate nohighlight">\(\vec{x} \in \mathbb{R}^{n}\)</span> into the subspace of <span class="math notranslate nohighlight">\(V\)</span> is denoted as <span class="math notranslate nohighlight">\({Proj}_{V}{\vec{x}} \in V\)</span>.</p>
<p>Since any vector in the subspace of <span class="math notranslate nohighlight">\(V\)</span> can be formulated as a linear combination of the basis vectors, we get</p>
<div class="amsmath math notranslate nohighlight" id="equation-c9ae4858-c9e0-4713-a78a-a4ba00f3f7c7">
<span class="eqno">(5)<a class="headerlink" href="#equation-c9ae4858-c9e0-4713-a78a-a4ba00f3f7c7" title="Permalink to this equation">¶</a></span>\[\begin{align}
    {Proj}_{V}{\vec{x}} &amp;= A\vec{y} \\
\end{align}\]</div>
<p>We also know that <span class="math notranslate nohighlight">\(\vec{x} = \underbrace{{Proj}_{V}{\vec{x}}}_{\in V} + \underbrace{{Proj}_{V^\complement}{\vec{x}}}_{\in V^\complement}\)</span>.</p>
<p>Furthermore, since <span class="math notranslate nohighlight">\(V\)</span> is the same as the column space of <span class="math notranslate nohighlight">\(A\)</span>, the matrix basis vectors that spans <span class="math notranslate nohighlight">\(V\)</span>, the complement of <span class="math notranslate nohighlight">\(V\)</span> is actually the nullspace of <span class="math notranslate nohighlight">\(A^\top\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7717340c-0e9b-4448-a05e-e3c2b50f77ff">
<span class="eqno">(6)<a class="headerlink" href="#equation-7717340c-0e9b-4448-a05e-e3c2b50f77ff" title="Permalink to this equation">¶</a></span>\[\begin{align}
    C(A) &amp;= V \\
    V^\complement &amp;= {(C(A))}^\complement = N(A^\top) \\
\end{align}\]</div>
<p>From the definition of the nullspace,</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Theorem</p>
<p>If a matrix <span class="math notranslate nohighlight">\(A\)</span> has linearly independent columns (invertible via Invertible Matrix Theorem), then <span class="math notranslate nohighlight">\(A^\top A\)</span> is always invertible <span class="bibtex" id="id5">[linearal7:online]</span>.</p>
<p>Proof:</p>
<p>By Invertible Matrix Theorem,</p>
<div class="amsmath math notranslate nohighlight" id="equation-b289a7df-0efa-43b2-b5b1-41e3d3fef3c2">
<span class="eqno">(7)<a class="headerlink" href="#equation-b289a7df-0efa-43b2-b5b1-41e3d3fef3c2" title="Permalink to this equation">¶</a></span>\[\begin{align}
    A\vec{x} &amp;= 0 \Rightarrow \vec{x} = 0 \\
    \therefore N(A^\top) &amp;= \vec{0}, A^\top A\vec{x} = 0 \iff \vec{x} = \vec{0} \\
\end{align}\]</div>
</div>
</div>
<div class="amsmath math notranslate nohighlight" id="equation-4f882b5b-f581-41a2-9eef-324495c649fb">
<span class="eqno">(8)<a class="headerlink" href="#equation-4f882b5b-f581-41a2-9eef-324495c649fb" title="Permalink to this equation">¶</a></span>\[\begin{align}
    A^\top \left({Proj}_{V^\complement}{\vec{x}}\right) &amp;= 0 \\
    A^\top \left(\vec{x} - {Proj}_{V}{\vec{x}}\right) &amp;= 0 \\
    A^\top \vec{x} - A^\top {Proj}_{V}{\vec{x}} &amp;= 0 \\
    A^\top \vec{x} - A^\top A\vec{y} &amp;= 0 \\
    A^\top \vec{x} &amp;= A^\top A\vec{y} \\
    \vec{y} &amp;= \underbrace{{(A^\top A)}^{-1}}_{\text{Invertible } \because A \text{ has linearly independent columns}} A^\top \vec{x} \\
\end{align}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-17ade257-0832-4c0d-9d85-cf36bc9a7ca9">
<span class="eqno">(9)<a class="headerlink" href="#equation-17ade257-0832-4c0d-9d85-cf36bc9a7ca9" title="Permalink to this equation">¶</a></span>\[\begin{align}
    {Proj}_{V}{\vec{x}} &amp;= A {(A^\top A)}^{-1} A^\top \vec{x} \\
\end{align}\]</div>
<p>Hence, we see that projections onto a subspace is a linear transformation.</p>
<p>Notice also, that if <span class="math notranslate nohighlight">\(A\)</span> was instead a vector <span class="math notranslate nohighlight">\(\vec{w} \in \mathbb{R}^{n}\)</span>, our formula in <code class="xref eq docutils literal notranslate"><span class="pre">13</span></code> reduces to the normal vector projection formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-26239455-070e-44e7-a565-c958c13f70b1">
<span class="eqno">(10)<a class="headerlink" href="#equation-26239455-070e-44e7-a565-c958c13f70b1" title="Permalink to this equation">¶</a></span>\[\begin{align}
    {Proj}_{\vec{w}}{\vec{x}} 
    &amp;= \vec{w} \underbrace{{(\vec{w}^\top \vec{w})}^{-1}}_{\text{Scalar}} \underbrace{\vec{w}^\top \vec{x}}_{\text{Scalar}} \\
    &amp;= \frac{\vec{w}^\top \vec{x}}{{\lVert \vec{w} \rVert}^2}\vec{w} \\
\end{align}\]</div>
</div>
<div class="section" id="applications-of-projections">
<h3>1.5.2. Applications of Projections<a class="headerlink" href="#applications-of-projections" title="Permalink to this headline">¶</a></h3>
<div class="section" id="geometric-interpretation-of-ordinary-least-squares-regression">
<h4>1.5.2.1 Geometric Interpretation of Ordinary Least Squares Regression<a class="headerlink" href="#geometric-interpretation-of-ordinary-least-squares-regression" title="Permalink to this headline">¶</a></h4>
<p><span class="bibtex" id="id6">[2Leastsq52:online]</span><span class="bibtex" id="id7">[ Ordinary7:online]</span></p>
<p>Given a dataset <span class="math notranslate nohighlight">\(\mathbf{X} = \left\{\mathbf{x}_{n} \vert \mathbf{x}_{n} \in \mathbb{R}^{D}, n \in 1, \cdots N \right\}\)</span> and response variables <span class="math notranslate nohighlight">\(\mathbf{y} = \left(y_1, \cdots, y_N\right)\)</span>, we model the following:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b0439696-82c9-4b9c-8612-9a88b2df7d23">
<span class="eqno">(11)<a class="headerlink" href="#equation-b0439696-82c9-4b9c-8612-9a88b2df7d23" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \mathbf{y} &amp;= \mathbf{X}\beta + \epsilon \\
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta\)</span> is a vector of coefficients of each feature / covariate / predictor / column in the data matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(\epsilon\)</span> is a vector of unobserved error random variables which explain the <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> outside of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.</p>
<p>Notice that in a perfect world, where <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is the only source of variation in <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, the linear regression / OLS model reduces to a regular inhomogeneous system of linear equations:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7c4fcf4e-bfba-4ace-b533-2b6ca221237c">
<span class="eqno">(12)<a class="headerlink" href="#equation-7c4fcf4e-bfba-4ace-b533-2b6ca221237c" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \mathbf{y} &amp;= \mathbf{X}\beta \\
\end{align}\]</div>
<p>However, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is often not a complete set of predictors for <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> and hence, we will most definitely get <span class="math notranslate nohighlight">\(\epsilon\)</span>. We can however, try to minimize <span class="math notranslate nohighlight">\(\epsilon\)</span> by finding a best fit <span class="math notranslate nohighlight">\(\beta\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6be9bd6e-fda6-4183-8b22-e165f4025662">
<span class="eqno">(13)<a class="headerlink" href="#equation-6be9bd6e-fda6-4183-8b22-e165f4025662" title="Permalink to this equation">¶</a></span>\[\begin{align}
    \hat{\beta} &amp;= \arg\underset{\beta}{\min} {\lVert \mathbf{y} - \mathbf{X} \beta \rVert}_{2} \\ 
\end{align}\]</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-machine-learning/01-linear-algebra-0"><dl class="citation">
<dt class="bibtex label" id="isb-bal41-online"><span class="brackets"><a class="fn-backref" href="#id2">2Is</a></span></dt>
<dd><p>(2) is bᵀb always positive definite? (also, messi makes a comeback!) - youtube. URL: <a class="reference external" href="https://www.youtube.com/watch?v=bp38BKP-xh4">https://www.youtube.com/watch?v=bp38BKP-xh4</a> (visited on 2021-04-07).</p>
</dd>
<dt class="bibtex label" id="forapos52-online"><span class="brackets"><a class="fn-backref" href="#id3">2Fo</a></span></dt>
<dd><p>(2) for a positive definite m, is bᵀmb always positive definite, too? - youtube. URL: <a class="reference external" href="https://www.youtube.com/watch?v=gu2llILc1tU">https://www.youtube.com/watch?v=gu2llILc1tU</a> (visited on 2021-04-07).</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./machine-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="00-intro.html" title="previous page">Machine Learning</a>
    <a class='right-next' id="next-link" href="02-probability-distributions.html" title="next page">2. Probability Distributions [Empty]</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chengyi (Jeff) Chen<br/>
        
            &copy; Copyright 2022.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>